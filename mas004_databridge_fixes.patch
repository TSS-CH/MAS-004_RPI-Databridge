diff --git a/.gitignore b/.gitignore
index 8863995..691d92d 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,42 +1,42 @@
-# Python
-__pycache__/
-*.pyc
-*.pyo
-*.pyd
-*.egg-info/
-dist/
-build/
-
-# venv
-.venv/
-venv/
-
-# OS / IDE
-.DS_Store
-.vscode/
-.idea/
-
-# Runtime data (NICHT versionieren!)
-/var/
-/logs/
-*.log
-*.sqlite
-*.db
-
-# Local config (enthält Tokens/Secrets)
-config.json
-/etc/mas004_rpi_databridge/config.json
-
-# Temp uploads
-/tmp/
-
-# Uvicorn / FastAPI runtime
-*.pid
-*.sock
-
-# Uploads, falls mal im Projektordner abgelegt
-uploads/
-*.xlsx
-
-# falls jemand config unter scripts/ testet
+# Python
+__pycache__/
+*.pyc
+*.pyo
+*.pyd
+*.egg-info/
+dist/
+build/
+
+# venv
+.venv/
+venv/
+
+# OS / IDE
+.DS_Store
+.vscode/
+.idea/
+
+# Runtime data (NICHT versionieren!)
+/var/
+/logs/
+*.log
+*.sqlite
+*.db
+
+# Local config (enthält Tokens/Secrets)
+config.json
+/etc/mas004_rpi_databridge/config.json
+
+# Temp uploads
+/tmp/
+
+# Uvicorn / FastAPI runtime
+*.pid
+*.sock
+
+# Uploads, falls mal im Projektordner abgelegt
+uploads/
+*.xlsx
+
+# falls jemand config unter scripts/ testet
 scripts/config.json
\ No newline at end of file
diff --git a/mas004_rpi_databridge/__init__.py b/mas004_rpi_databridge/__init__.py
index e51db7f..1288200 100644
--- a/mas004_rpi_databridge/__init__.py
+++ b/mas004_rpi_databridge/__init__.py
@@ -1 +1 @@
-__all__ = ["config", "db", "outbox", "inbox", "http_client", "watchdog", "webui", "service"]
+__all__ = ["config", "db", "outbox", "inbox", "http_client", "watchdog", "webui", "service"]
diff --git a/mas004_rpi_databridge/config.py b/mas004_rpi_databridge/config.py
index 1bec984..b51cfa1 100644
--- a/mas004_rpi_databridge/config.py
+++ b/mas004_rpi_databridge/config.py
@@ -43,6 +43,17 @@ class Settings:
     retry_base_s: float = 1.0
     retry_cap_s: float = 60.0
 
+    # Device endpoints (optional; editable in UI)
+    # ESP-PLC (HTTP)
+    esp_host: str = ""
+    esp_port: int = 0
+
+    # Printers
+    vj3350_host: str = ""
+    vj3350_port: int = 0
+    vj6530_host: str = ""
+    vj6530_port: int = 0
+
     # UI/API auth
     ui_token: str = "change-me"
     shared_secret: str = ""
diff --git a/mas004_rpi_databridge/db.py b/mas004_rpi_databridge/db.py
index 0a778d8..45bc4d7 100644
--- a/mas004_rpi_databridge/db.py
+++ b/mas004_rpi_databridge/db.py
@@ -1,108 +1,108 @@
-import sqlite3
-import time
-import threading
-
-SCHEMA = """
-CREATE TABLE IF NOT EXISTS outbox (
-  id INTEGER PRIMARY KEY AUTOINCREMENT,
-  created_ts REAL NOT NULL,
-  method TEXT NOT NULL,
-  url TEXT NOT NULL,
-  headers_json TEXT NOT NULL,
-  body_json TEXT,
-  idempotency_key TEXT NOT NULL,
-  retry_count INTEGER NOT NULL DEFAULT 0,
-  next_attempt_ts REAL NOT NULL DEFAULT 0
-);
-CREATE INDEX IF NOT EXISTS idx_outbox_next ON outbox(next_attempt_ts, created_ts);
-
-CREATE TABLE IF NOT EXISTS inbox (
-  id INTEGER PRIMARY KEY AUTOINCREMENT,
-  received_ts REAL NOT NULL,
-  source TEXT,
-  headers_json TEXT NOT NULL,
-  body_json TEXT,
-  idempotency_key TEXT NOT NULL,
-  state TEXT NOT NULL DEFAULT 'pending'
-);
-CREATE UNIQUE INDEX IF NOT EXISTS idx_inbox_dedupe ON inbox(idempotency_key);
-CREATE INDEX IF NOT EXISTS idx_inbox_state ON inbox(state, received_ts);
-
-CREATE TABLE IF NOT EXISTS logs (
-  id INTEGER PRIMARY KEY AUTOINCREMENT,
-  ts REAL NOT NULL,
-  channel TEXT NOT NULL,
-  direction TEXT NOT NULL,
-  message TEXT NOT NULL
-);
-CREATE INDEX IF NOT EXISTS idx_logs_ts ON logs(ts);
-CREATE INDEX IF NOT EXISTS idx_logs_ch_ts ON logs(channel, ts);
-
--- ===== Parameter-Tabellen =====
-CREATE TABLE IF NOT EXISTS params (
-  pkey TEXT PRIMARY KEY,          -- z.B. TTP00002
-  ptype TEXT NOT NULL,            -- z.B. TTP
-  pid TEXT NOT NULL,              -- z.B. 00002
-  min_v REAL,
-  max_v REAL,
-  default_v TEXT,
-  unit TEXT,
-  rw TEXT,                        -- R / W / R/W
-  dtype TEXT,
-  name TEXT,
-  format_relevant TEXT,
-  message TEXT,
-  possible_cause TEXT,
-  effects TEXT,
-  remedy TEXT,
-  updated_ts REAL NOT NULL
-);
-CREATE INDEX IF NOT EXISTS idx_params_type_id ON params(ptype, pid);
-
-CREATE TABLE IF NOT EXISTS param_values (
-  pkey TEXT PRIMARY KEY,
-  value TEXT NOT NULL,
-  updated_ts REAL NOT NULL,
-  FOREIGN KEY(pkey) REFERENCES params(pkey) ON DELETE CASCADE
-);
-"""
-
-_init_lock = threading.Lock()
-_initialized_paths = set()
-
-
-class DB:
-    def __init__(self, path: str):
-        self.path = path
-        self._init_once()
-
-    def _conn(self):
-        # isolation_level=None => autocommit
-        c = sqlite3.connect(self.path, timeout=30, isolation_level=None)
-        c.execute("PRAGMA busy_timeout=5000;")
-        c.execute("PRAGMA journal_mode=WAL;")
-        c.execute("PRAGMA synchronous=NORMAL;")
-        return c
-
-    def _init_once(self):
-        global _initialized_paths
-        with _init_lock:
-            if self.path in _initialized_paths:
-                return
-
-            # Retry a few times if another thread/process is initializing
-            for i in range(10):
-                try:
-                    with self._conn() as c:
-                        c.executescript(SCHEMA)
-                    _initialized_paths.add(self.path)
-                    return
-                except sqlite3.OperationalError as e:
-                    if "locked" in str(e).lower():
-                        time.sleep(0.2 * (i + 1))
-                        continue
-                    raise
-
-
-def now_ts() -> float:
-    return time.time()
+import sqlite3
+import time
+import threading
+
+SCHEMA = """
+CREATE TABLE IF NOT EXISTS outbox (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  created_ts REAL NOT NULL,
+  method TEXT NOT NULL,
+  url TEXT NOT NULL,
+  headers_json TEXT NOT NULL,
+  body_json TEXT,
+  idempotency_key TEXT NOT NULL,
+  retry_count INTEGER NOT NULL DEFAULT 0,
+  next_attempt_ts REAL NOT NULL DEFAULT 0
+);
+CREATE INDEX IF NOT EXISTS idx_outbox_next ON outbox(next_attempt_ts, created_ts);
+
+CREATE TABLE IF NOT EXISTS inbox (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  received_ts REAL NOT NULL,
+  source TEXT,
+  headers_json TEXT NOT NULL,
+  body_json TEXT,
+  idempotency_key TEXT NOT NULL,
+  state TEXT NOT NULL DEFAULT 'pending'
+);
+CREATE UNIQUE INDEX IF NOT EXISTS idx_inbox_dedupe ON inbox(idempotency_key);
+CREATE INDEX IF NOT EXISTS idx_inbox_state ON inbox(state, received_ts);
+
+CREATE TABLE IF NOT EXISTS logs (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  ts REAL NOT NULL,
+  channel TEXT NOT NULL,
+  direction TEXT NOT NULL,
+  message TEXT NOT NULL
+);
+CREATE INDEX IF NOT EXISTS idx_logs_ts ON logs(ts);
+CREATE INDEX IF NOT EXISTS idx_logs_ch_ts ON logs(channel, ts);
+
+-- ===== Parameter-Tabellen =====
+CREATE TABLE IF NOT EXISTS params (
+  pkey TEXT PRIMARY KEY,          -- z.B. TTP00002
+  ptype TEXT NOT NULL,            -- z.B. TTP
+  pid TEXT NOT NULL,              -- z.B. 00002
+  min_v REAL,
+  max_v REAL,
+  default_v TEXT,
+  unit TEXT,
+  rw TEXT,                        -- R / W / R/W
+  dtype TEXT,
+  name TEXT,
+  format_relevant TEXT,
+  message TEXT,
+  possible_cause TEXT,
+  effects TEXT,
+  remedy TEXT,
+  updated_ts REAL NOT NULL
+);
+CREATE INDEX IF NOT EXISTS idx_params_type_id ON params(ptype, pid);
+
+CREATE TABLE IF NOT EXISTS param_values (
+  pkey TEXT PRIMARY KEY,
+  value TEXT NOT NULL,
+  updated_ts REAL NOT NULL,
+  FOREIGN KEY(pkey) REFERENCES params(pkey) ON DELETE CASCADE
+);
+"""
+
+_init_lock = threading.Lock()
+_initialized_paths = set()
+
+
+class DB:
+    def __init__(self, path: str):
+        self.path = path
+        self._init_once()
+
+    def _conn(self):
+        # isolation_level=None => autocommit
+        c = sqlite3.connect(self.path, timeout=30, isolation_level=None)
+        c.execute("PRAGMA busy_timeout=5000;")
+        c.execute("PRAGMA journal_mode=WAL;")
+        c.execute("PRAGMA synchronous=NORMAL;")
+        return c
+
+    def _init_once(self):
+        global _initialized_paths
+        with _init_lock:
+            if self.path in _initialized_paths:
+                return
+
+            # Retry a few times if another thread/process is initializing
+            for i in range(10):
+                try:
+                    with self._conn() as c:
+                        c.executescript(SCHEMA)
+                    _initialized_paths.add(self.path)
+                    return
+                except sqlite3.OperationalError as e:
+                    if "locked" in str(e).lower():
+                        time.sleep(0.2 * (i + 1))
+                        continue
+                    raise
+
+
+def now_ts() -> float:
+    return time.time()
diff --git a/mas004_rpi_databridge/http_client.py b/mas004_rpi_databridge/http_client.py
index 1d61a8f..73f47b0 100644
--- a/mas004_rpi_databridge/http_client.py
+++ b/mas004_rpi_databridge/http_client.py
@@ -1,36 +1,36 @@
-# mas004_rpi_databridge/http_client.py
-from __future__ import annotations
-
-from typing import Optional, Dict, Any
-import httpx
-
-
-class HttpClient:
-    def __init__(self, timeout_s: float = 10.0, source_ip: str = "", verify_tls: bool = True):
-        self.timeout_s = float(timeout_s or 10.0)
-        self.source_ip = (source_ip or "").strip()
-        self.verify_tls = bool(verify_tls)
-
-        self._timeout = httpx.Timeout(self.timeout_s)
-
-        # Optional: an eth0 IP binden (source address)
-        self._transport = None
-        if self.source_ip:
-            # httpx/httpcore erwartet i.d.R. (host, port)
-            self._transport = httpx.HTTPTransport(local_address=(self.source_ip, 0))
-
-    def request(self, method: str, url: str, headers: Dict[str, str], body: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
-        method = (method or "POST").upper()
-        headers = dict(headers or {})
-
-        # WICHTIG: verify_tls=False => verify=False (self-signed ok)
-        verify = False if not self.verify_tls else True
-
-        with httpx.Client(timeout=self._timeout, verify=verify, transport=self._transport) as c:
-            r = c.request(method, url, headers=headers, json=body)
-
-        # Fehler sauber hochwerfen, damit dein Outbox-Backoff greift
-        if not (200 <= r.status_code < 300):
-            raise RuntimeError(f"HTTP {r.status_code}: {r.text[:400]}")
-
-        return {"status_code": r.status_code, "text": r.text}
+# mas004_rpi_databridge/http_client.py
+from __future__ import annotations
+
+from typing import Optional, Dict, Any
+import httpx
+
+
+class HttpClient:
+    def __init__(self, timeout_s: float = 10.0, source_ip: str = "", verify_tls: bool = True):
+        self.timeout_s = float(timeout_s or 10.0)
+        self.source_ip = (source_ip or "").strip()
+        self.verify_tls = bool(verify_tls)
+
+        self._timeout = httpx.Timeout(self.timeout_s)
+
+        # Optional: an eth0 IP binden (source address)
+        self._transport = None
+        if self.source_ip:
+            # httpx/httpcore erwartet i.d.R. (host, port)
+            self._transport = httpx.HTTPTransport(local_address=(self.source_ip, 0))
+
+    def request(self, method: str, url: str, headers: Dict[str, str], body: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        method = (method or "POST").upper()
+        headers = dict(headers or {})
+
+        # WICHTIG: verify_tls=False => verify=False (self-signed ok)
+        verify = False if not self.verify_tls else True
+
+        with httpx.Client(timeout=self._timeout, verify=verify, transport=self._transport) as c:
+            r = c.request(method, url, headers=headers, json=body)
+
+        # Fehler sauber hochwerfen, damit dein Outbox-Backoff greift
+        if not (200 <= r.status_code < 300):
+            raise RuntimeError(f"HTTP {r.status_code}: {r.text[:400]}")
+
+        return {"status_code": r.status_code, "text": r.text}
diff --git a/mas004_rpi_databridge/inbox.py b/mas004_rpi_databridge/inbox.py
index 13e3042..07638cd 100644
--- a/mas004_rpi_databridge/inbox.py
+++ b/mas004_rpi_databridge/inbox.py
@@ -1,79 +1,79 @@
-import json
-from dataclasses import dataclass
-from typing import Optional
-from mas004_rpi_databridge.db import DB, now_ts
-
-@dataclass
-class InboxMsg:
-    id: int
-    received_ts: float
-    source: Optional[str]
-    headers_json: str
-    body_json: Optional[str]
-    idempotency_key: str
-    state: str
-
-class Inbox:
-    def __init__(self, db: DB):
-        self.db = db
-
-    def store(self, source: Optional[str], headers: dict, body: Optional[dict], idempotency_key: str) -> bool:
-        headers = dict(headers or {})
-        with self.db._conn() as c:
-            try:
-                c.execute(
-                    "INSERT INTO inbox(received_ts,source,headers_json,body_json,idempotency_key,state) VALUES(?,?,?,?,?, 'pending')",
-                    (now_ts(), source, json.dumps(headers), json.dumps(body) if body is not None else None, idempotency_key)
-                )
-                return True
-            except Exception:
-                # likely UNIQUE constraint -> duplicate idempotency key
-                return False
-
-    def next_pending(self) -> Optional[InboxMsg]:
-        with self.db._conn() as c:
-            row = c.execute(
-                """SELECT id,received_ts,source,headers_json,body_json,idempotency_key,state
-                   FROM inbox
-                   WHERE state='pending'
-                   ORDER BY received_ts ASC
-                   LIMIT 1"""
-            ).fetchone()
-        return InboxMsg(*row) if row else None
-
-    def claim_next_pending(self) -> Optional[InboxMsg]:
-        """
-        Atomar: nimmt die älteste pending Nachricht und setzt sie auf 'processing',
-        damit parallel laufende Worker sie nicht doppelt ziehen.
-        """
-        with self.db._conn() as c:
-            c.execute("BEGIN IMMEDIATE;")
-            row = c.execute(
-                """SELECT id,received_ts,source,headers_json,body_json,idempotency_key,state
-                   FROM inbox
-                   WHERE state='pending'
-                   ORDER BY received_ts ASC
-                   LIMIT 1"""
-            ).fetchone()
-            if not row:
-                c.execute("COMMIT;")
-                return None
-
-            msg_id = row[0]
-            c.execute("UPDATE inbox SET state='processing' WHERE id=? AND state='pending'", (msg_id,))
-            c.execute("COMMIT;")
-
-        return InboxMsg(*row)
-
-    def ack(self, msg_id: int):
-        with self.db._conn() as c:
-            c.execute("UPDATE inbox SET state='done' WHERE id=?", (msg_id,))
-
-    def nack(self, msg_id: int):
-        # falls du mal retry willst
-        with self.db._conn() as c:
-            c.execute("UPDATE inbox SET state='pending' WHERE id=?", (msg_id,))
-
-    def count_pending(self) -> int:
-        with self.db._conn() as c:
-            return int(c.execute("SELECT COUNT(*) FROM inbox WHERE state='pending'").fetchone()[0])
+import json
+from dataclasses import dataclass
+from typing import Optional
+from mas004_rpi_databridge.db import DB, now_ts
+
+@dataclass
+class InboxMsg:
+    id: int
+    received_ts: float
+    source: Optional[str]
+    headers_json: str
+    body_json: Optional[str]
+    idempotency_key: str
+    state: str
+
+class Inbox:
+    def __init__(self, db: DB):
+        self.db = db
+
+    def store(self, source: Optional[str], headers: dict, body: Optional[dict], idempotency_key: str) -> bool:
+        headers = dict(headers or {})
+        with self.db._conn() as c:
+            try:
+                c.execute(
+                    "INSERT INTO inbox(received_ts,source,headers_json,body_json,idempotency_key,state) VALUES(?,?,?,?,?, 'pending')",
+                    (now_ts(), source, json.dumps(headers), json.dumps(body) if body is not None else None, idempotency_key)
+                )
+                return True
+            except Exception:
+                # likely UNIQUE constraint -> duplicate idempotency key
+                return False
+
+    def next_pending(self) -> Optional[InboxMsg]:
+        with self.db._conn() as c:
+            row = c.execute(
+                """SELECT id,received_ts,source,headers_json,body_json,idempotency_key,state
+                   FROM inbox
+                   WHERE state='pending'
+                   ORDER BY received_ts ASC
+                   LIMIT 1"""
+            ).fetchone()
+        return InboxMsg(*row) if row else None
+
+    def claim_next_pending(self) -> Optional[InboxMsg]:
+        """
+        Atomar: nimmt die älteste pending Nachricht und setzt sie auf 'processing',
+        damit parallel laufende Worker sie nicht doppelt ziehen.
+        """
+        with self.db._conn() as c:
+            c.execute("BEGIN IMMEDIATE;")
+            row = c.execute(
+                """SELECT id,received_ts,source,headers_json,body_json,idempotency_key,state
+                   FROM inbox
+                   WHERE state='pending'
+                   ORDER BY received_ts ASC
+                   LIMIT 1"""
+            ).fetchone()
+            if not row:
+                c.execute("COMMIT;")
+                return None
+
+            msg_id = row[0]
+            c.execute("UPDATE inbox SET state='processing' WHERE id=? AND state='pending'", (msg_id,))
+            c.execute("COMMIT;")
+
+        return InboxMsg(*row)
+
+    def ack(self, msg_id: int):
+        with self.db._conn() as c:
+            c.execute("UPDATE inbox SET state='done' WHERE id=?", (msg_id,))
+
+    def nack(self, msg_id: int):
+        # falls du mal retry willst
+        with self.db._conn() as c:
+            c.execute("UPDATE inbox SET state='pending' WHERE id=?", (msg_id,))
+
+    def count_pending(self) -> int:
+        with self.db._conn() as c:
+            return int(c.execute("SELECT COUNT(*) FROM inbox WHERE state='pending'").fetchone()[0])
diff --git a/mas004_rpi_databridge/logs.py b/mas004_rpi_databridge/logs.py
index 3d7bc07..9a38a24 100644
--- a/mas004_rpi_databridge/logs.py
+++ b/mas004_rpi_databridge/logs.py
@@ -1,33 +1,33 @@
-import os
-import time
-import json
-from collections import deque
-
-DEFAULT_LOGDIR = "/var/log/mas004_rpi_databridge"
-
-def ensure_dir(path: str):
-    os.makedirs(path, exist_ok=True)
-
-class LogBus:
-    def __init__(self, logdir: str = DEFAULT_LOGDIR, mem_keep: int = 500):
-        self.logdir = logdir
-        ensure_dir(self.logdir)
-        self.mem = { }  # component -> deque
-        self.mem_keep = mem_keep
-
-    def write(self, component: str, direction: str, text: str, extra=None):
-        ts = time.time()
-        rec = {"ts": ts, "dir": direction, "text": text, "extra": extra or {}}
-        if component not in self.mem:
-            self.mem[component] = deque(maxlen=self.mem_keep)
-        self.mem[component].append(rec)
-
-        fn = os.path.join(self.logdir, f"{component}.log")
-        with open(fn, "a", encoding="utf-8") as f:
-            f.write(json.dumps(rec, ensure_ascii=False) + "\n")
-
-    def tail_mem(self, component: str, n: int = 200):
-        q = self.mem.get(component)
-        if not q:
-            return []
-        return list(q)[-n:]
+import os
+import time
+import json
+from collections import deque
+
+DEFAULT_LOGDIR = "/var/log/mas004_rpi_databridge"
+
+def ensure_dir(path: str):
+    os.makedirs(path, exist_ok=True)
+
+class LogBus:
+    def __init__(self, logdir: str = DEFAULT_LOGDIR, mem_keep: int = 500):
+        self.logdir = logdir
+        ensure_dir(self.logdir)
+        self.mem = { }  # component -> deque
+        self.mem_keep = mem_keep
+
+    def write(self, component: str, direction: str, text: str, extra=None):
+        ts = time.time()
+        rec = {"ts": ts, "dir": direction, "text": text, "extra": extra or {}}
+        if component not in self.mem:
+            self.mem[component] = deque(maxlen=self.mem_keep)
+        self.mem[component].append(rec)
+
+        fn = os.path.join(self.logdir, f"{component}.log")
+        with open(fn, "a", encoding="utf-8") as f:
+            f.write(json.dumps(rec, ensure_ascii=False) + "\n")
+
+    def tail_mem(self, component: str, n: int = 200):
+        q = self.mem.get(component)
+        if not q:
+            return []
+        return list(q)[-n:]
diff --git a/mas004_rpi_databridge/logstore.py b/mas004_rpi_databridge/logstore.py
index f8abe21..b7ba2ce 100644
--- a/mas004_rpi_databridge/logstore.py
+++ b/mas004_rpi_databridge/logstore.py
@@ -1,88 +1,88 @@
-import os
-from typing import List, Dict, Any
-from mas004_rpi_databridge.db import DB, now_ts
-
-DEFAULT_LOG_DIR = "/var/lib/mas004_rpi_databridge/logs"
-
-
-class LogStore:
-    def __init__(self, db: DB, log_dir: str = DEFAULT_LOG_DIR):
-        self.db = db
-        self.log_dir = log_dir
-        os.makedirs(self.log_dir, exist_ok=True)
-
-    def log(self, channel: str, direction: str, message: str):
-        ts = now_ts()
-        # DB
-        with self.db._conn() as c:
-            c.execute(
-                "INSERT INTO logs(ts, channel, direction, message) VALUES (?,?,?,?)",
-                (ts, channel, direction, message)
-            )
-            # Retention: pro Channel nur die letzten ~5000 Einträge
-            c.execute(
-                """DELETE FROM logs
-                   WHERE channel=?
-                     AND id NOT IN (
-                       SELECT id FROM logs WHERE channel=? ORDER BY id DESC LIMIT 5000
-                     )""",
-                (channel, channel)
-            )
-
-        # Datei
-        fn = os.path.join(self.log_dir, f"{channel}.log")
-        line = f"{ts:.3f}\t{direction.upper()}\t{message}\n"
-        try:
-            with open(fn, "a", encoding="utf-8") as f:
-                f.write(line)
-        except Exception:
-            pass
-
-    def list_logs(self, channel: str, limit: int = 200) -> List[Dict[str, Any]]:
-        limit = max(1, min(int(limit), 2000))
-        with self.db._conn() as c:
-            rows = c.execute(
-                "SELECT ts, direction, message FROM logs WHERE channel=? ORDER BY ts DESC LIMIT ?",
-                (channel, limit)
-            ).fetchall()
-        # newest first -> return oldest first
-        return [{"ts": r[0], "direction": r[1], "message": r[2]} for r in rows[::-1]]
-
-    def read_logfile(self, channel: str, max_bytes: int = 500_000) -> str:
-        fn = os.path.join(self.log_dir, f"{channel}.log")
-        if not os.path.exists(fn):
-            return ""
-        with open(fn, "rb") as f:
-            data = f.read()
-        if len(data) > max_bytes:
-            data = data[-max_bytes:]
-        return data.decode("utf-8", errors="replace")
-
-    def clear_channel(self, channel: str) -> Dict[str, Any]:
-        # DB clear
-        with self.db._conn() as c:
-            c.execute("DELETE FROM logs WHERE channel=?", (channel,))
-
-        # file clear
-        fn = os.path.join(self.log_dir, f"{channel}.log")
-        try:
-            if os.path.exists(fn):
-                os.remove(fn)
-        except Exception:
-            pass
-        return {"ok": True}
-
-    def list_channels(self) -> List[str]:
-        # channels from DB + files
-        ch = set()
-        with self.db._conn() as c:
-            rows = c.execute("SELECT DISTINCT channel FROM logs").fetchall()
-            for r in rows:
-                ch.add(str(r[0]))
-        try:
-            for fn in os.listdir(self.log_dir):
-                if fn.endswith(".log"):
-                    ch.add(fn[:-4])
-        except Exception:
-            pass
-        return sorted(ch)
+import os
+from typing import List, Dict, Any
+from mas004_rpi_databridge.db import DB, now_ts
+
+DEFAULT_LOG_DIR = "/var/lib/mas004_rpi_databridge/logs"
+
+
+class LogStore:
+    def __init__(self, db: DB, log_dir: str = DEFAULT_LOG_DIR):
+        self.db = db
+        self.log_dir = log_dir
+        os.makedirs(self.log_dir, exist_ok=True)
+
+    def log(self, channel: str, direction: str, message: str):
+        ts = now_ts()
+        # DB
+        with self.db._conn() as c:
+            c.execute(
+                "INSERT INTO logs(ts, channel, direction, message) VALUES (?,?,?,?)",
+                (ts, channel, direction, message)
+            )
+            # Retention: pro Channel nur die letzten ~5000 Einträge
+            c.execute(
+                """DELETE FROM logs
+                   WHERE channel=?
+                     AND id NOT IN (
+                       SELECT id FROM logs WHERE channel=? ORDER BY id DESC LIMIT 5000
+                     )""",
+                (channel, channel)
+            )
+
+        # Datei
+        fn = os.path.join(self.log_dir, f"{channel}.log")
+        line = f"{ts:.3f}\t{direction.upper()}\t{message}\n"
+        try:
+            with open(fn, "a", encoding="utf-8") as f:
+                f.write(line)
+        except Exception:
+            pass
+
+    def list_logs(self, channel: str, limit: int = 200) -> List[Dict[str, Any]]:
+        limit = max(1, min(int(limit), 2000))
+        with self.db._conn() as c:
+            rows = c.execute(
+                "SELECT ts, direction, message FROM logs WHERE channel=? ORDER BY ts DESC LIMIT ?",
+                (channel, limit)
+            ).fetchall()
+        # newest first -> return oldest first
+        return [{"ts": r[0], "direction": r[1], "message": r[2]} for r in rows[::-1]]
+
+    def read_logfile(self, channel: str, max_bytes: int = 500_000) -> str:
+        fn = os.path.join(self.log_dir, f"{channel}.log")
+        if not os.path.exists(fn):
+            return ""
+        with open(fn, "rb") as f:
+            data = f.read()
+        if len(data) > max_bytes:
+            data = data[-max_bytes:]
+        return data.decode("utf-8", errors="replace")
+
+    def clear_channel(self, channel: str) -> Dict[str, Any]:
+        # DB clear
+        with self.db._conn() as c:
+            c.execute("DELETE FROM logs WHERE channel=?", (channel,))
+
+        # file clear
+        fn = os.path.join(self.log_dir, f"{channel}.log")
+        try:
+            if os.path.exists(fn):
+                os.remove(fn)
+        except Exception:
+            pass
+        return {"ok": True}
+
+    def list_channels(self) -> List[str]:
+        # channels from DB + files
+        ch = set()
+        with self.db._conn() as c:
+            rows = c.execute("SELECT DISTINCT channel FROM logs").fetchall()
+            for r in rows:
+                ch.add(str(r[0]))
+        try:
+            for fn in os.listdir(self.log_dir):
+                if fn.endswith(".log"):
+                    ch.add(fn[:-4])
+        except Exception:
+            pass
+        return sorted(ch)
diff --git a/mas004_rpi_databridge/netconfig.py b/mas004_rpi_databridge/netconfig.py
index d220da0..dd8b57a 100644
--- a/mas004_rpi_databridge/netconfig.py
+++ b/mas004_rpi_databridge/netconfig.py
@@ -1,173 +1,173 @@
-import os
-import re
-import shutil
-import subprocess
-from dataclasses import dataclass
-from typing import Optional, Dict, Any, Tuple
-
-
-@dataclass
-class IfaceCfg:
-    ip: str
-    prefix: int
-    gw: str
-
-
-def _run(cmd: list, check=True) -> subprocess.CompletedProcess:
-    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=check)
-
-
-def has_nmcli() -> bool:
-    return shutil.which("nmcli") is not None
-
-
-def _iface_name(kind: str) -> str:
-    # in deinem Projekt ist es eth0/eth1 – falls später umbenannt, hier zentral ändern
-    kind = (kind or "").lower().strip()
-    if kind in ("eth0", "0"):
-        return "eth0"
-    if kind in ("eth1", "1"):
-        return "eth1"
-    return kind
-
-
-def _validate_ipv4(ip: str) -> bool:
-    try:
-        parts = [int(p) for p in ip.split(".")]
-        return len(parts) == 4 and all(0 <= p <= 255 for p in parts)
-    except Exception:
-        return False
-
-
-def _validate_prefix(prefix: int) -> bool:
-    return isinstance(prefix, int) and 0 <= prefix <= 32
-
-
-def validate_iface_cfg(cfg: IfaceCfg) -> Tuple[bool, str]:
-    if not _validate_ipv4(cfg.ip):
-        return False, "Invalid IP"
-    if not _validate_ipv4(cfg.gw):
-        return False, "Invalid Gateway"
-    if not _validate_prefix(cfg.prefix):
-        return False, "Invalid Prefix (0..32)"
-    return True, "OK"
-
-
-def get_current_ip_info() -> Dict[str, Any]:
-    """
-    Best-effort read-only status.
-    """
-    out: Dict[str, Any] = {"ok": True, "ifaces": {}}
-    for iface in ("eth0", "eth1"):
-        try:
-            ip = _run(["bash", "-lc", f"ip -4 addr show {iface} | grep -oP '(?<=inet\\s)\\d+\\.\\d+\\.\\d+\\.\\d+/\\d+' | head -n1"], check=False).stdout.strip()
-            gw = _run(["bash", "-lc", f"ip route | grep '^default' | grep {iface} | awk '{{print $3}}' | head -n1"], check=False).stdout.strip()
-            out["ifaces"][iface] = {"cidr": ip or "", "gw": gw or ""}
-        except Exception as e:
-            out["ifaces"][iface] = {"cidr": "", "gw": "", "err": repr(e)}
-    out["nmcli"] = has_nmcli()
-    return out
-
-
-# -----------------------------
-# Apply using NetworkManager (nmcli)
-# -----------------------------
-def _nmcli_find_connection_for_iface(iface: str) -> Optional[str]:
-    """
-    Finds a NM connection name bound to device.
-    """
-    try:
-        r = _run(["bash", "-lc", f"nmcli -t -f NAME,DEVICE con show | grep ':{iface}$' | head -n1"], check=False).stdout.strip()
-        if not r:
-            return None
-        return r.split(":")[0].strip() or None
-    except Exception:
-        return None
-
-
-def apply_static_nmcli(iface: str, cfg: IfaceCfg) -> Dict[str, Any]:
-    iface = _iface_name(iface)
-    ok, msg = validate_iface_cfg(cfg)
-    if not ok:
-        return {"ok": False, "msg": msg}
-
-    con = _nmcli_find_connection_for_iface(iface)
-    if not con:
-        return {"ok": False, "msg": f"nmcli: no connection bound to {iface}. Open NetworkManager and bind first, or use dhcpcd fallback."}
-
-    cidr = f"{cfg.ip}/{cfg.prefix}"
-    try:
-        _run(["bash", "-lc", f"nmcli con mod '{con}' ipv4.method manual ipv4.addresses '{cidr}' ipv4.gateway '{cfg.gw}' ipv4.dns ''"], check=True)
-        _run(["bash", "-lc", f"nmcli con down '{con}' || true"], check=False)
-        _run(["bash", "-lc", f"nmcli con up '{con}'"], check=True)
-        return {"ok": True, "msg": f"Applied via nmcli on {iface} ({con})", "cidr": cidr, "gw": cfg.gw}
-    except Exception as e:
-        return {"ok": False, "msg": f"nmcli apply failed: {repr(e)}"}
-
-
-# -----------------------------
-# Fallback: dhcpcd.conf editing
-# -----------------------------
-DHCPCD_PATH = "/etc/dhcpcd.conf"
-
-
-def apply_static_dhcpcd(iface: str, cfg: IfaceCfg) -> Dict[str, Any]:
-    iface = _iface_name(iface)
-    ok, msg = validate_iface_cfg(cfg)
-    if not ok:
-        return {"ok": False, "msg": msg}
-
-    cidr = f"{cfg.ip}/{cfg.prefix}"
-
-    if not os.path.exists(DHCPCD_PATH):
-        return {"ok": False, "msg": f"{DHCPCD_PATH} not found. Install dhcpcd or use nmcli."}
-
-    try:
-        with open(DHCPCD_PATH, "r", encoding="utf-8") as f:
-            txt = f.read()
-
-        backup = DHCPCD_PATH + ".bak"
-        with open(backup, "w", encoding="utf-8") as f:
-            f.write(txt)
-
-        # Remove old block for iface
-        pattern = re.compile(rf"(?ms)^\s*#\s*MAS004-BEGIN\s+{re.escape(iface)}\s*$.*?^\s*#\s*MAS004-END\s+{re.escape(iface)}\s*$\s*")
-        txt = re.sub(pattern, "", txt)
-
-        block = (
-            f"# MAS004-BEGIN {iface}\n"
-            f"interface {iface}\n"
-            f"static ip_address={cidr}\n"
-            f"static routers={cfg.gw}\n"
-            f"# MAS004-END {iface}\n"
-        )
-
-        txt = txt.rstrip() + "\n\n" + block + "\n"
-
-        with open(DHCPCD_PATH, "w", encoding="utf-8") as f:
-            f.write(txt)
-
-        # restart networking
-        _run(["bash", "-lc", "systemctl restart dhcpcd || true"], check=False)
-        _run(["bash", "-lc", "systemctl restart networking || true"], check=False)
-
-        return {"ok": True, "msg": f"Applied via dhcpcd.conf on {iface} (backup: {backup})", "cidr": cidr, "gw": cfg.gw}
-    except Exception as e:
-        return {"ok": False, "msg": f"dhcpcd apply failed: {repr(e)}"}
-
-
-def apply_static(iface: str, cfg: IfaceCfg) -> Dict[str, Any]:
-    """
-    Prefers nmcli, falls back to dhcpcd.
-    """
-    if has_nmcli():
-        res = apply_static_nmcli(iface, cfg)
-        if res.get("ok"):
-            return res
-        # if nmcli exists but couldn't apply -> try dhcpcd
-        res2 = apply_static_dhcpcd(iface, cfg)
-        res2["note"] = "nmcli failed, tried dhcpcd fallback"
-        res2["nmcli_error"] = res.get("msg")
-        return res2
-
-    return apply_static_dhcpcd(iface, cfg)
+import os
+import re
+import shutil
+import subprocess
+from dataclasses import dataclass
+from typing import Optional, Dict, Any, Tuple
+
+
+@dataclass
+class IfaceCfg:
+    ip: str
+    prefix: int
+    gw: str
+
+
+def _run(cmd: list, check=True) -> subprocess.CompletedProcess:
+    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=check)
+
+
+def has_nmcli() -> bool:
+    return shutil.which("nmcli") is not None
+
+
+def _iface_name(kind: str) -> str:
+    # in deinem Projekt ist es eth0/eth1 – falls später umbenannt, hier zentral ändern
+    kind = (kind or "").lower().strip()
+    if kind in ("eth0", "0"):
+        return "eth0"
+    if kind in ("eth1", "1"):
+        return "eth1"
+    return kind
+
+
+def _validate_ipv4(ip: str) -> bool:
+    try:
+        parts = [int(p) for p in ip.split(".")]
+        return len(parts) == 4 and all(0 <= p <= 255 for p in parts)
+    except Exception:
+        return False
+
+
+def _validate_prefix(prefix: int) -> bool:
+    return isinstance(prefix, int) and 0 <= prefix <= 32
+
+
+def validate_iface_cfg(cfg: IfaceCfg) -> Tuple[bool, str]:
+    if not _validate_ipv4(cfg.ip):
+        return False, "Invalid IP"
+    if not _validate_ipv4(cfg.gw):
+        return False, "Invalid Gateway"
+    if not _validate_prefix(cfg.prefix):
+        return False, "Invalid Prefix (0..32)"
+    return True, "OK"
+
+
+def get_current_ip_info() -> Dict[str, Any]:
+    """
+    Best-effort read-only status.
+    """
+    out: Dict[str, Any] = {"ok": True, "ifaces": {}}
+    for iface in ("eth0", "eth1"):
+        try:
+            ip = _run(["bash", "-lc", f"ip -4 addr show {iface} | grep -oP '(?<=inet\\s)\\d+\\.\\d+\\.\\d+\\.\\d+/\\d+' | head -n1"], check=False).stdout.strip()
+            gw = _run(["bash", "-lc", f"ip route | grep '^default' | grep {iface} | awk '{{print $3}}' | head -n1"], check=False).stdout.strip()
+            out["ifaces"][iface] = {"cidr": ip or "", "gw": gw or ""}
+        except Exception as e:
+            out["ifaces"][iface] = {"cidr": "", "gw": "", "err": repr(e)}
+    out["nmcli"] = has_nmcli()
+    return out
+
+
+# -----------------------------
+# Apply using NetworkManager (nmcli)
+# -----------------------------
+def _nmcli_find_connection_for_iface(iface: str) -> Optional[str]:
+    """
+    Finds a NM connection name bound to device.
+    """
+    try:
+        r = _run(["bash", "-lc", f"nmcli -t -f NAME,DEVICE con show | grep ':{iface}$' | head -n1"], check=False).stdout.strip()
+        if not r:
+            return None
+        return r.split(":")[0].strip() or None
+    except Exception:
+        return None
+
+
+def apply_static_nmcli(iface: str, cfg: IfaceCfg) -> Dict[str, Any]:
+    iface = _iface_name(iface)
+    ok, msg = validate_iface_cfg(cfg)
+    if not ok:
+        return {"ok": False, "msg": msg}
+
+    con = _nmcli_find_connection_for_iface(iface)
+    if not con:
+        return {"ok": False, "msg": f"nmcli: no connection bound to {iface}. Open NetworkManager and bind first, or use dhcpcd fallback."}
+
+    cidr = f"{cfg.ip}/{cfg.prefix}"
+    try:
+        _run(["bash", "-lc", f"nmcli con mod '{con}' ipv4.method manual ipv4.addresses '{cidr}' ipv4.gateway '{cfg.gw}' ipv4.dns ''"], check=True)
+        _run(["bash", "-lc", f"nmcli con down '{con}' || true"], check=False)
+        _run(["bash", "-lc", f"nmcli con up '{con}'"], check=True)
+        return {"ok": True, "msg": f"Applied via nmcli on {iface} ({con})", "cidr": cidr, "gw": cfg.gw}
+    except Exception as e:
+        return {"ok": False, "msg": f"nmcli apply failed: {repr(e)}"}
+
+
+# -----------------------------
+# Fallback: dhcpcd.conf editing
+# -----------------------------
+DHCPCD_PATH = "/etc/dhcpcd.conf"
+
+
+def apply_static_dhcpcd(iface: str, cfg: IfaceCfg) -> Dict[str, Any]:
+    iface = _iface_name(iface)
+    ok, msg = validate_iface_cfg(cfg)
+    if not ok:
+        return {"ok": False, "msg": msg}
+
+    cidr = f"{cfg.ip}/{cfg.prefix}"
+
+    if not os.path.exists(DHCPCD_PATH):
+        return {"ok": False, "msg": f"{DHCPCD_PATH} not found. Install dhcpcd or use nmcli."}
+
+    try:
+        with open(DHCPCD_PATH, "r", encoding="utf-8") as f:
+            txt = f.read()
+
+        backup = DHCPCD_PATH + ".bak"
+        with open(backup, "w", encoding="utf-8") as f:
+            f.write(txt)
+
+        # Remove old block for iface
+        pattern = re.compile(rf"(?ms)^\s*#\s*MAS004-BEGIN\s+{re.escape(iface)}\s*$.*?^\s*#\s*MAS004-END\s+{re.escape(iface)}\s*$\s*")
+        txt = re.sub(pattern, "", txt)
+
+        block = (
+            f"# MAS004-BEGIN {iface}\n"
+            f"interface {iface}\n"
+            f"static ip_address={cidr}\n"
+            f"static routers={cfg.gw}\n"
+            f"# MAS004-END {iface}\n"
+        )
+
+        txt = txt.rstrip() + "\n\n" + block + "\n"
+
+        with open(DHCPCD_PATH, "w", encoding="utf-8") as f:
+            f.write(txt)
+
+        # restart networking
+        _run(["bash", "-lc", "systemctl restart dhcpcd || true"], check=False)
+        _run(["bash", "-lc", "systemctl restart networking || true"], check=False)
+
+        return {"ok": True, "msg": f"Applied via dhcpcd.conf on {iface} (backup: {backup})", "cidr": cidr, "gw": cfg.gw}
+    except Exception as e:
+        return {"ok": False, "msg": f"dhcpcd apply failed: {repr(e)}"}
+
+
+def apply_static(iface: str, cfg: IfaceCfg) -> Dict[str, Any]:
+    """
+    Prefers nmcli, falls back to dhcpcd.
+    """
+    if has_nmcli():
+        res = apply_static_nmcli(iface, cfg)
+        if res.get("ok"):
+            return res
+        # if nmcli exists but couldn't apply -> try dhcpcd
+        res2 = apply_static_dhcpcd(iface, cfg)
+        res2["note"] = "nmcli failed, tried dhcpcd fallback"
+        res2["nmcli_error"] = res.get("msg")
+        return res2
+
+    return apply_static_dhcpcd(iface, cfg)
diff --git a/mas004_rpi_databridge/outbox.py b/mas004_rpi_databridge/outbox.py
index 71847bc..010f2da 100644
--- a/mas004_rpi_databridge/outbox.py
+++ b/mas004_rpi_databridge/outbox.py
@@ -1,61 +1,61 @@
-import json
-import uuid
-from dataclasses import dataclass
-from typing import Optional
-from mas004_rpi_databridge.db import DB, now_ts
-
-@dataclass
-class OutboxJob:
-    id: int
-    created_ts: float
-    method: str
-    url: str
-    headers_json: str
-    body_json: Optional[str]
-    idempotency_key: str
-    retry_count: int
-    next_attempt_ts: float
-
-class Outbox:
-    def __init__(self, db: DB):
-        self.db = db
-
-    def enqueue(self, method: str, url: str, headers: dict, body: Optional[dict], idempotency_key: Optional[str]=None):
-        if idempotency_key is None:
-            idempotency_key = str(uuid.uuid4())
-
-        headers = dict(headers or {})
-        headers.setdefault("X-Idempotency-Key", idempotency_key)
-        headers.setdefault("Content-Type", "application/json")
-
-        with self.db._conn() as c:
-            c.execute(
-                "INSERT INTO outbox(created_ts,method,url,headers_json,body_json,idempotency_key) VALUES(?,?,?,?,?,?)",
-                (now_ts(), method.upper(), url, json.dumps(headers), json.dumps(body) if body is not None else None, idempotency_key)
-            )
-        return idempotency_key
-
-    def next_due(self) -> Optional[OutboxJob]:
-        with self.db._conn() as c:
-            row = c.execute(
-                """SELECT id,created_ts,method,url,headers_json,body_json,idempotency_key,retry_count,next_attempt_ts
-                   FROM outbox
-                   WHERE next_attempt_ts <= ?
-                   ORDER BY next_attempt_ts ASC, created_ts ASC
-                   LIMIT 1""",
-                (now_ts(),)
-            ).fetchone()
-        return OutboxJob(*row) if row else None
-
-    def delete(self, job_id: int):
-        with self.db._conn() as c:
-            c.execute("DELETE FROM outbox WHERE id=?", (job_id,))
-
-    def reschedule(self, job_id: int, retry_count: int, next_attempt_ts: float):
-        with self.db._conn() as c:
-            c.execute("UPDATE outbox SET retry_count=?, next_attempt_ts=? WHERE id=?",
-                      (retry_count, next_attempt_ts, job_id))
-
-    def count(self) -> int:
-        with self.db._conn() as c:
-            return int(c.execute("SELECT COUNT(*) FROM outbox").fetchone()[0])
+import json
+import uuid
+from dataclasses import dataclass
+from typing import Optional
+from mas004_rpi_databridge.db import DB, now_ts
+
+@dataclass
+class OutboxJob:
+    id: int
+    created_ts: float
+    method: str
+    url: str
+    headers_json: str
+    body_json: Optional[str]
+    idempotency_key: str
+    retry_count: int
+    next_attempt_ts: float
+
+class Outbox:
+    def __init__(self, db: DB):
+        self.db = db
+
+    def enqueue(self, method: str, url: str, headers: dict, body: Optional[dict], idempotency_key: Optional[str]=None):
+        if idempotency_key is None:
+            idempotency_key = str(uuid.uuid4())
+
+        headers = dict(headers or {})
+        headers.setdefault("X-Idempotency-Key", idempotency_key)
+        headers.setdefault("Content-Type", "application/json")
+
+        with self.db._conn() as c:
+            c.execute(
+                "INSERT INTO outbox(created_ts,method,url,headers_json,body_json,idempotency_key) VALUES(?,?,?,?,?,?)",
+                (now_ts(), method.upper(), url, json.dumps(headers), json.dumps(body) if body is not None else None, idempotency_key)
+            )
+        return idempotency_key
+
+    def next_due(self) -> Optional[OutboxJob]:
+        with self.db._conn() as c:
+            row = c.execute(
+                """SELECT id,created_ts,method,url,headers_json,body_json,idempotency_key,retry_count,next_attempt_ts
+                   FROM outbox
+                   WHERE next_attempt_ts <= ?
+                   ORDER BY next_attempt_ts ASC, created_ts ASC
+                   LIMIT 1""",
+                (now_ts(),)
+            ).fetchone()
+        return OutboxJob(*row) if row else None
+
+    def delete(self, job_id: int):
+        with self.db._conn() as c:
+            c.execute("DELETE FROM outbox WHERE id=?", (job_id,))
+
+    def reschedule(self, job_id: int, retry_count: int, next_attempt_ts: float):
+        with self.db._conn() as c:
+            c.execute("UPDATE outbox SET retry_count=?, next_attempt_ts=? WHERE id=?",
+                      (retry_count, next_attempt_ts, job_id))
+
+    def count(self) -> int:
+        with self.db._conn() as c:
+            return int(c.execute("SELECT COUNT(*) FROM outbox").fetchone()[0])
diff --git a/mas004_rpi_databridge/params.py b/mas004_rpi_databridge/params.py
index 97ab08c..f64907f 100644
--- a/mas004_rpi_databridge/params.py
+++ b/mas004_rpi_databridge/params.py
@@ -1,335 +1,335 @@
-import io
-import re
-from typing import Optional, Dict, Any, Tuple, List
-
-import openpyxl
-
-from mas004_rpi_databridge.db import DB, now_ts
-
-SHEET_NAME = "Parameter"
-
-
-def _to_str(v) -> Optional[str]:
-    if v is None:
-        return None
-    if isinstance(v, float) and v.is_integer():
-        return str(int(v))
-    return str(v)
-
-
-def _to_float(v) -> Optional[float]:
-    if v is None:
-        return None
-    try:
-        return float(v)
-    except Exception:
-        return None
-
-
-def _norm_header(s: str) -> str:
-    s = (s or "").strip().lower()
-    s = re.sub(r"[^a-z0-9]+", "_", s)
-    return s.strip("_")
-
-
-class ParamStore:
-    def __init__(self, db: DB):
-        self.db = db
-
-    def import_xlsx(self, file_path: str) -> Dict[str, Any]:
-        wb = openpyxl.load_workbook(file_path, data_only=True)
-        if SHEET_NAME not in wb.sheetnames:
-            raise RuntimeError(f"Excel-Sheet '{SHEET_NAME}' nicht gefunden. Vorhanden: {wb.sheetnames}")
-        ws = wb[SHEET_NAME]
-
-        inserted = 0
-        updated = 0
-        skipped = 0
-
-        headers_raw = [(_to_str(ws.cell(1, c).value) or "").strip() for c in range(1, ws.max_column + 1)]
-        header_map: Dict[str, int] = {}
-        for i, h in enumerate(headers_raw, start=1):
-            nh = _norm_header(h)
-            if nh:
-                header_map[nh] = i
-
-        def col_any(*names: str) -> Optional[int]:
-            for n in names:
-                nn = _norm_header(n)
-                if nn in header_map:
-                    return header_map[nn]
-            for want in names:
-                want2 = (want or "").strip().lower()
-                for idx, h in enumerate(headers_raw, start=1):
-                    if (h or "").strip().lower() == want2:
-                        return idx
-            return None
-
-        c_type = col_any("Params_Type.", "Params_Type.:", "Params Type", "Params_Type")
-        c_id   = col_any("Param ID.", "Param. ID.:", "Param. ID.", "Param ID", "Param_ID", "Param. ID")
-
-        c_min   = col_any("Min.", "Min.:", "Min")
-        c_max   = col_any("Max.", "Max.:", "Max")
-        c_def   = col_any("Default Value", "Default Value:", "Default")
-        c_unit  = col_any("Einheit", "Unit")
-        c_rw    = col_any("R/W:", "R/W", "RW", "R_W")
-        c_dtype = col_any("Data Type", "DataType", "Datatype")
-        c_name  = col_any("Name")
-        c_fmt   = col_any("Format relevant?", "Format relevant", "Format")
-        c_msg   = col_any("Message")
-        c_cause = col_any("Possible Cause", "Possible cause")
-        c_eff   = col_any("Effects", "Effect")
-        c_rem   = col_any("Remedy")
-
-        if not c_type or not c_id:
-            raise RuntimeError(
-                "Pflichtspalten fehlen. Erwartet (varianten): 'Params_Type' und 'Param ID'. "
-                f"Gefunden (normalisiert): {sorted(list(header_map.keys()))}"
-            )
-
-        with self.db._conn() as c:
-            for r in range(2, ws.max_row + 1):
-                ptype = (_to_str(ws.cell(r, c_type).value) or "").strip()
-                pid = (_to_str(ws.cell(r, c_id).value) or "").strip()
-
-                if not ptype and not pid:
-                    continue
-                if not ptype or not pid:
-                    skipped += 1
-                    continue
-
-                pkey = f"{ptype}{pid}"
-
-                min_v = _to_float(ws.cell(r, c_min).value) if c_min else None
-                max_v = _to_float(ws.cell(r, c_max).value) if c_max else None
-                default_v = _to_str(ws.cell(r, c_def).value) if c_def else None
-                unit = _to_str(ws.cell(r, c_unit).value) if c_unit else None
-                rw = _to_str(ws.cell(r, c_rw).value) if c_rw else None
-                dtype = _to_str(ws.cell(r, c_dtype).value) if c_dtype else None
-                name = _to_str(ws.cell(r, c_name).value) if c_name else None
-                fmt = _to_str(ws.cell(r, c_fmt).value) if c_fmt else None
-                msg = _to_str(ws.cell(r, c_msg).value) if c_msg else None
-                cause = _to_str(ws.cell(r, c_cause).value) if c_cause else None
-                eff = _to_str(ws.cell(r, c_eff).value) if c_eff else None
-                rem = _to_str(ws.cell(r, c_rem).value) if c_rem else None
-
-                ts = now_ts()
-
-                exists = c.execute("SELECT 1 FROM params WHERE pkey=?", (pkey,)).fetchone() is not None
-                if exists:
-                    c.execute(
-                        """UPDATE params SET
-                           ptype=?, pid=?, min_v=?, max_v=?, default_v=?, unit=?, rw=?, dtype=?,
-                           name=?, format_relevant=?, message=?, possible_cause=?, effects=?, remedy=?,
-                           updated_ts=?
-                           WHERE pkey=?""",
-                        (ptype, pid, min_v, max_v, default_v, unit, rw, dtype, name, fmt, msg, cause, eff, rem, ts, pkey)
-                    )
-                    updated += 1
-                else:
-                    c.execute(
-                        """INSERT INTO params(
-                           pkey,ptype,pid,min_v,max_v,default_v,unit,rw,dtype,name,format_relevant,
-                           message,possible_cause,effects,remedy,updated_ts
-                           )
-                           VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)""",
-                        (pkey, ptype, pid, min_v, max_v, default_v, unit, rw, dtype, name, fmt, msg, cause, eff, rem, ts)
-                    )
-                    inserted += 1
-
-        return {"ok": True, "inserted": inserted, "updated": updated, "skipped": skipped}
-
-    def get_meta(self, pkey: str) -> Optional[Dict[str, Any]]:
-        with self.db._conn() as c:
-            row = c.execute(
-                """SELECT pkey,ptype,pid,min_v,max_v,default_v,unit,rw,dtype,name,format_relevant,message
-                   FROM params WHERE pkey=?""",
-                (pkey,)
-            ).fetchone()
-        if not row:
-            return None
-        keys = ["pkey","ptype","pid","min_v","max_v","default_v","unit","rw","dtype","name","format_relevant","message"]
-        return dict(zip(keys, row))
-
-    def get_value(self, pkey: str) -> Optional[str]:
-        with self.db._conn() as c:
-            row = c.execute("SELECT value FROM param_values WHERE pkey=?", (pkey,)).fetchone()
-        return row[0] if row else None
-
-    def get_effective_value(self, pkey: str) -> str:
-        v = self.get_value(pkey)
-        if v is not None:
-            return v
-        meta = self.get_meta(pkey)
-        dv = (meta or {}).get("default_v")
-        return dv if dv is not None else "0"
-
-    def set_value(self, pkey: str, value: str) -> Tuple[bool, str]:
-        meta = self.get_meta(pkey)
-        if not meta:
-            return False, "NAK_UnknownParam"
-
-        rw = (meta.get("rw") or "").strip().upper()
-        if rw == "R":
-            return False, "NAK_ReadOnly"
-
-        min_v = meta.get("min_v")
-        max_v = meta.get("max_v")
-        try:
-            fv = float(value)
-            if min_v is not None and fv < float(min_v):
-                return False, "NAK_OutOfRange"
-            if max_v is not None and fv > float(max_v):
-                return False, "NAK_OutOfRange"
-        except Exception:
-            pass
-
-        with self.db._conn() as c:
-            c.execute(
-                "INSERT INTO param_values(pkey,value,updated_ts) VALUES(?,?,?) "
-                "ON CONFLICT(pkey) DO UPDATE SET value=excluded.value, updated_ts=excluded.updated_ts",
-                (pkey, str(value), now_ts())
-            )
-        return True, "OK"
-
-    def update_meta(
-        self,
-        pkey: str,
-        default_v: Optional[str] = None,
-        min_v: Optional[float] = None,
-        max_v: Optional[float] = None,
-        rw: Optional[str] = None,
-    ) -> Tuple[bool, str]:
-        meta = self.get_meta(pkey)
-        if not meta:
-            return False, "NAK_UnknownParam"
-
-        new_min = meta.get("min_v") if min_v is None else min_v
-        new_max = meta.get("max_v") if max_v is None else max_v
-        new_def = meta.get("default_v") if default_v is None else str(default_v)
-        new_rw = meta.get("rw") if rw is None else str(rw).strip()
-
-        # rw normalisieren
-        if new_rw is not None:
-            rwu = new_rw.strip().upper()
-            if rwu in ("RW", "R_W", "R/W"):
-                rwu = "R/W"
-            if rwu not in ("R", "W", "R/W", ""):
-                return False, "NAK_BadRW"
-            new_rw = rwu if rwu else None
-
-        # min/max check
-        if new_min is not None and new_max is not None:
-            if float(new_min) > float(new_max):
-                return False, "NAK_MinGreaterThanMax"
-
-        # default range check (nur wenn numeric)
-        try:
-            fv = float(new_def) if new_def is not None else None
-            if fv is not None:
-                if new_min is not None and fv < float(new_min):
-                    return False, "NAK_DefaultOutOfRange"
-                if new_max is not None and fv > float(new_max):
-                    return False, "NAK_DefaultOutOfRange"
-        except Exception:
-            pass
-
-        with self.db._conn() as c:
-            c.execute(
-                """UPDATE params
-                   SET default_v=?, min_v=?, max_v=?, rw=?, updated_ts=?
-                   WHERE pkey=?""",
-                (new_def, new_min, new_max, new_rw, now_ts(), pkey)
-            )
-        return True, "OK"
-
-    def list_params(self, ptype: Optional[str] = None, q: Optional[str] = None, limit: int = 200, offset: int = 0):
-        limit = max(1, min(int(limit), 1000))
-        offset = max(0, int(offset))
-        where = []
-        args = []
-
-        if ptype:
-            where.append("ptype=?")
-            args.append(ptype)
-
-        if q:
-            q2 = f"%{q}%"
-            where.append("(pkey LIKE ? OR name LIKE ? OR message LIKE ?)")
-            args.extend([q2, q2, q2])
-
-        wsql = ("WHERE " + " AND ".join(where)) if where else ""
-        sql = f"""SELECT pkey,ptype,pid,min_v,max_v,default_v,unit,rw,dtype,name,message
-                  FROM params
-                  {wsql}
-                  ORDER BY ptype ASC, pid ASC
-                  LIMIT ? OFFSET ?"""
-        args.extend([limit, offset])
-
-        with self.db._conn() as c:
-            rows = c.execute(sql, args).fetchall()
-
-        out = []
-        for r in rows:
-            pkey = r[0]
-            cur = self.get_value(pkey)
-            eff = cur if cur is not None else (r[5] if r[5] is not None else "0")
-            out.append({
-                "pkey": r[0],
-                "ptype": r[1],
-                "pid": r[2],
-                "min_v": r[3],
-                "max_v": r[4],
-                "default_v": r[5],
-                "current_v": cur,
-                "effective_v": eff,
-                "unit": r[6],
-                "rw": r[7],
-                "dtype": r[8],
-                "name": r[9],
-                "message": r[10],
-            })
-        return out
-
-    def export_xlsx_bytes(self, ptype: Optional[str] = None, q: Optional[str] = None) -> bytes:
-        rows = self.list_params(ptype=ptype, q=q, limit=100000, offset=0)
-
-        wb = openpyxl.Workbook()
-        ws = wb.active
-        ws.title = SHEET_NAME
-
-        headers = [
-            "Params_Type.:",
-            "Param. ID.:",
-            "Min.:",
-            "Max.:",
-            "Default Value",
-            "Current Value",
-            "Effective Value",
-            "Einheit",
-            "R/W:",
-            "Data Type",
-            "Name",
-            "Message",
-        ]
-        ws.append(headers)
-
-        for r in rows:
-            ws.append([
-                r.get("ptype"),
-                r.get("pid"),
-                r.get("min_v"),
-                r.get("max_v"),
-                r.get("default_v"),
-                r.get("current_v"),
-                r.get("effective_v"),
-                r.get("unit"),
-                r.get("rw"),
-                r.get("dtype"),
-                r.get("name"),
-                r.get("message"),
-            ])
-
-        bio = io.BytesIO()
-        wb.save(bio)
-        return bio.getvalue()
+import io
+import re
+from typing import Optional, Dict, Any, Tuple, List
+
+import openpyxl
+
+from mas004_rpi_databridge.db import DB, now_ts
+
+SHEET_NAME = "Parameter"
+
+
+def _to_str(v) -> Optional[str]:
+    if v is None:
+        return None
+    if isinstance(v, float) and v.is_integer():
+        return str(int(v))
+    return str(v)
+
+
+def _to_float(v) -> Optional[float]:
+    if v is None:
+        return None
+    try:
+        return float(v)
+    except Exception:
+        return None
+
+
+def _norm_header(s: str) -> str:
+    s = (s or "").strip().lower()
+    s = re.sub(r"[^a-z0-9]+", "_", s)
+    return s.strip("_")
+
+
+class ParamStore:
+    def __init__(self, db: DB):
+        self.db = db
+
+    def import_xlsx(self, file_path: str) -> Dict[str, Any]:
+        wb = openpyxl.load_workbook(file_path, data_only=True)
+        if SHEET_NAME not in wb.sheetnames:
+            raise RuntimeError(f"Excel-Sheet '{SHEET_NAME}' nicht gefunden. Vorhanden: {wb.sheetnames}")
+        ws = wb[SHEET_NAME]
+
+        inserted = 0
+        updated = 0
+        skipped = 0
+
+        headers_raw = [(_to_str(ws.cell(1, c).value) or "").strip() for c in range(1, ws.max_column + 1)]
+        header_map: Dict[str, int] = {}
+        for i, h in enumerate(headers_raw, start=1):
+            nh = _norm_header(h)
+            if nh:
+                header_map[nh] = i
+
+        def col_any(*names: str) -> Optional[int]:
+            for n in names:
+                nn = _norm_header(n)
+                if nn in header_map:
+                    return header_map[nn]
+            for want in names:
+                want2 = (want or "").strip().lower()
+                for idx, h in enumerate(headers_raw, start=1):
+                    if (h or "").strip().lower() == want2:
+                        return idx
+            return None
+
+        c_type = col_any("Params_Type.", "Params_Type.:", "Params Type", "Params_Type")
+        c_id   = col_any("Param ID.", "Param. ID.:", "Param. ID.", "Param ID", "Param_ID", "Param. ID")
+
+        c_min   = col_any("Min.", "Min.:", "Min")
+        c_max   = col_any("Max.", "Max.:", "Max")
+        c_def   = col_any("Default Value", "Default Value:", "Default")
+        c_unit  = col_any("Einheit", "Unit")
+        c_rw    = col_any("R/W:", "R/W", "RW", "R_W")
+        c_dtype = col_any("Data Type", "DataType", "Datatype")
+        c_name  = col_any("Name")
+        c_fmt   = col_any("Format relevant?", "Format relevant", "Format")
+        c_msg   = col_any("Message")
+        c_cause = col_any("Possible Cause", "Possible cause")
+        c_eff   = col_any("Effects", "Effect")
+        c_rem   = col_any("Remedy")
+
+        if not c_type or not c_id:
+            raise RuntimeError(
+                "Pflichtspalten fehlen. Erwartet (varianten): 'Params_Type' und 'Param ID'. "
+                f"Gefunden (normalisiert): {sorted(list(header_map.keys()))}"
+            )
+
+        with self.db._conn() as c:
+            for r in range(2, ws.max_row + 1):
+                ptype = (_to_str(ws.cell(r, c_type).value) or "").strip()
+                pid = (_to_str(ws.cell(r, c_id).value) or "").strip()
+
+                if not ptype and not pid:
+                    continue
+                if not ptype or not pid:
+                    skipped += 1
+                    continue
+
+                pkey = f"{ptype}{pid}"
+
+                min_v = _to_float(ws.cell(r, c_min).value) if c_min else None
+                max_v = _to_float(ws.cell(r, c_max).value) if c_max else None
+                default_v = _to_str(ws.cell(r, c_def).value) if c_def else None
+                unit = _to_str(ws.cell(r, c_unit).value) if c_unit else None
+                rw = _to_str(ws.cell(r, c_rw).value) if c_rw else None
+                dtype = _to_str(ws.cell(r, c_dtype).value) if c_dtype else None
+                name = _to_str(ws.cell(r, c_name).value) if c_name else None
+                fmt = _to_str(ws.cell(r, c_fmt).value) if c_fmt else None
+                msg = _to_str(ws.cell(r, c_msg).value) if c_msg else None
+                cause = _to_str(ws.cell(r, c_cause).value) if c_cause else None
+                eff = _to_str(ws.cell(r, c_eff).value) if c_eff else None
+                rem = _to_str(ws.cell(r, c_rem).value) if c_rem else None
+
+                ts = now_ts()
+
+                exists = c.execute("SELECT 1 FROM params WHERE pkey=?", (pkey,)).fetchone() is not None
+                if exists:
+                    c.execute(
+                        """UPDATE params SET
+                           ptype=?, pid=?, min_v=?, max_v=?, default_v=?, unit=?, rw=?, dtype=?,
+                           name=?, format_relevant=?, message=?, possible_cause=?, effects=?, remedy=?,
+                           updated_ts=?
+                           WHERE pkey=?""",
+                        (ptype, pid, min_v, max_v, default_v, unit, rw, dtype, name, fmt, msg, cause, eff, rem, ts, pkey)
+                    )
+                    updated += 1
+                else:
+                    c.execute(
+                        """INSERT INTO params(
+                           pkey,ptype,pid,min_v,max_v,default_v,unit,rw,dtype,name,format_relevant,
+                           message,possible_cause,effects,remedy,updated_ts
+                           )
+                           VALUES(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)""",
+                        (pkey, ptype, pid, min_v, max_v, default_v, unit, rw, dtype, name, fmt, msg, cause, eff, rem, ts)
+                    )
+                    inserted += 1
+
+        return {"ok": True, "inserted": inserted, "updated": updated, "skipped": skipped}
+
+    def get_meta(self, pkey: str) -> Optional[Dict[str, Any]]:
+        with self.db._conn() as c:
+            row = c.execute(
+                """SELECT pkey,ptype,pid,min_v,max_v,default_v,unit,rw,dtype,name,format_relevant,message
+                   FROM params WHERE pkey=?""",
+                (pkey,)
+            ).fetchone()
+        if not row:
+            return None
+        keys = ["pkey","ptype","pid","min_v","max_v","default_v","unit","rw","dtype","name","format_relevant","message"]
+        return dict(zip(keys, row))
+
+    def get_value(self, pkey: str) -> Optional[str]:
+        with self.db._conn() as c:
+            row = c.execute("SELECT value FROM param_values WHERE pkey=?", (pkey,)).fetchone()
+        return row[0] if row else None
+
+    def get_effective_value(self, pkey: str) -> str:
+        v = self.get_value(pkey)
+        if v is not None:
+            return v
+        meta = self.get_meta(pkey)
+        dv = (meta or {}).get("default_v")
+        return dv if dv is not None else "0"
+
+    def set_value(self, pkey: str, value: str) -> Tuple[bool, str]:
+        meta = self.get_meta(pkey)
+        if not meta:
+            return False, "NAK_UnknownParam"
+
+        rw = (meta.get("rw") or "").strip().upper()
+        if rw == "R":
+            return False, "NAK_ReadOnly"
+
+        min_v = meta.get("min_v")
+        max_v = meta.get("max_v")
+        try:
+            fv = float(value)
+            if min_v is not None and fv < float(min_v):
+                return False, "NAK_OutOfRange"
+            if max_v is not None and fv > float(max_v):
+                return False, "NAK_OutOfRange"
+        except Exception:
+            pass
+
+        with self.db._conn() as c:
+            c.execute(
+                "INSERT INTO param_values(pkey,value,updated_ts) VALUES(?,?,?) "
+                "ON CONFLICT(pkey) DO UPDATE SET value=excluded.value, updated_ts=excluded.updated_ts",
+                (pkey, str(value), now_ts())
+            )
+        return True, "OK"
+
+    def update_meta(
+        self,
+        pkey: str,
+        default_v: Optional[str] = None,
+        min_v: Optional[float] = None,
+        max_v: Optional[float] = None,
+        rw: Optional[str] = None,
+    ) -> Tuple[bool, str]:
+        meta = self.get_meta(pkey)
+        if not meta:
+            return False, "NAK_UnknownParam"
+
+        new_min = meta.get("min_v") if min_v is None else min_v
+        new_max = meta.get("max_v") if max_v is None else max_v
+        new_def = meta.get("default_v") if default_v is None else str(default_v)
+        new_rw = meta.get("rw") if rw is None else str(rw).strip()
+
+        # rw normalisieren
+        if new_rw is not None:
+            rwu = new_rw.strip().upper()
+            if rwu in ("RW", "R_W", "R/W"):
+                rwu = "R/W"
+            if rwu not in ("R", "W", "R/W", ""):
+                return False, "NAK_BadRW"
+            new_rw = rwu if rwu else None
+
+        # min/max check
+        if new_min is not None and new_max is not None:
+            if float(new_min) > float(new_max):
+                return False, "NAK_MinGreaterThanMax"
+
+        # default range check (nur wenn numeric)
+        try:
+            fv = float(new_def) if new_def is not None else None
+            if fv is not None:
+                if new_min is not None and fv < float(new_min):
+                    return False, "NAK_DefaultOutOfRange"
+                if new_max is not None and fv > float(new_max):
+                    return False, "NAK_DefaultOutOfRange"
+        except Exception:
+            pass
+
+        with self.db._conn() as c:
+            c.execute(
+                """UPDATE params
+                   SET default_v=?, min_v=?, max_v=?, rw=?, updated_ts=?
+                   WHERE pkey=?""",
+                (new_def, new_min, new_max, new_rw, now_ts(), pkey)
+            )
+        return True, "OK"
+
+    def list_params(self, ptype: Optional[str] = None, q: Optional[str] = None, limit: int = 200, offset: int = 0):
+        limit = max(1, min(int(limit), 1000))
+        offset = max(0, int(offset))
+        where = []
+        args = []
+
+        if ptype:
+            where.append("ptype=?")
+            args.append(ptype)
+
+        if q:
+            q2 = f"%{q}%"
+            where.append("(pkey LIKE ? OR name LIKE ? OR message LIKE ?)")
+            args.extend([q2, q2, q2])
+
+        wsql = ("WHERE " + " AND ".join(where)) if where else ""
+        sql = f"""SELECT pkey,ptype,pid,min_v,max_v,default_v,unit,rw,dtype,name,message
+                  FROM params
+                  {wsql}
+                  ORDER BY ptype ASC, pid ASC
+                  LIMIT ? OFFSET ?"""
+        args.extend([limit, offset])
+
+        with self.db._conn() as c:
+            rows = c.execute(sql, args).fetchall()
+
+        out = []
+        for r in rows:
+            pkey = r[0]
+            cur = self.get_value(pkey)
+            eff = cur if cur is not None else (r[5] if r[5] is not None else "0")
+            out.append({
+                "pkey": r[0],
+                "ptype": r[1],
+                "pid": r[2],
+                "min_v": r[3],
+                "max_v": r[4],
+                "default_v": r[5],
+                "current_v": cur,
+                "effective_v": eff,
+                "unit": r[6],
+                "rw": r[7],
+                "dtype": r[8],
+                "name": r[9],
+                "message": r[10],
+            })
+        return out
+
+    def export_xlsx_bytes(self, ptype: Optional[str] = None, q: Optional[str] = None) -> bytes:
+        rows = self.list_params(ptype=ptype, q=q, limit=100000, offset=0)
+
+        wb = openpyxl.Workbook()
+        ws = wb.active
+        ws.title = SHEET_NAME
+
+        headers = [
+            "Params_Type.:",
+            "Param. ID.:",
+            "Min.:",
+            "Max.:",
+            "Default Value",
+            "Current Value",
+            "Effective Value",
+            "Einheit",
+            "R/W:",
+            "Data Type",
+            "Name",
+            "Message",
+        ]
+        ws.append(headers)
+
+        for r in rows:
+            ws.append([
+                r.get("ptype"),
+                r.get("pid"),
+                r.get("min_v"),
+                r.get("max_v"),
+                r.get("default_v"),
+                r.get("current_v"),
+                r.get("effective_v"),
+                r.get("unit"),
+                r.get("rw"),
+                r.get("dtype"),
+                r.get("name"),
+                r.get("message"),
+            ])
+
+        bio = io.BytesIO()
+        wb.save(bio)
+        return bio.getvalue()
diff --git a/mas004_rpi_databridge/params_store.py b/mas004_rpi_databridge/params_store.py
index da51482..5e5961e 100644
--- a/mas004_rpi_databridge/params_store.py
+++ b/mas004_rpi_databridge/params_store.py
@@ -1,140 +1,140 @@
-import os
-import sqlite3
-from typing import Optional, Dict, Any, List, Tuple
-from contextlib import contextmanager
-import openpyxl
-
-def _colnames(cur, table: str) -> List[str]:
-    rows = cur.execute(f"PRAGMA table_info({table})").fetchall()
-    return [r[1] for r in rows]
-
-class ParamStore:
-    def __init__(self, db):
-        self.db = db
-        self.ensure_schema()
-
-    def ensure_schema(self):
-        with self.db._conn() as c:
-            c.execute("""
-            CREATE TABLE IF NOT EXISTS params(
-              ptype TEXT NOT NULL,
-              pid   TEXT NOT NULL,
-              min_v REAL,
-              max_v REAL,
-              rw    TEXT,
-              default_value TEXT,
-              current_value TEXT,
-              description TEXT,
-              PRIMARY KEY (ptype, pid)
-            )""")
-
-    def get(self, ptype: str, pid: str) -> Optional[Dict[str, Any]]:
-        with self.db._conn() as c:
-            row = c.execute("""
-                SELECT ptype,pid,min_v,max_v,rw,default_value,current_value,description
-                FROM params WHERE ptype=? AND pid=?""", (ptype, pid)).fetchone()
-        if not row:
-            return None
-        keys = ["ptype","pid","min_v","max_v","rw","default_value","current_value","description"]
-        return dict(zip(keys, row))
-
-    def set_current(self, ptype: str, pid: str, value: str):
-        with self.db._conn() as c:
-            c.execute("""
-              UPDATE params SET current_value=? WHERE ptype=? AND pid=?""",
-              (str(value), ptype, pid)
-            )
-
-    def upsert(self, rec: Dict[str, Any]):
-        with self.db._conn() as c:
-            c.execute("""
-              INSERT INTO params(ptype,pid,min_v,max_v,rw,default_value,current_value,description)
-              VALUES(?,?,?,?,?,?,?,?)
-              ON CONFLICT(ptype,pid) DO UPDATE SET
-                min_v=excluded.min_v,
-                max_v=excluded.max_v,
-                rw=excluded.rw,
-                default_value=excluded.default_value,
-                current_value=excluded.current_value,
-                description=excluded.description
-            """, (
-                rec["ptype"], rec["pid"],
-                rec.get("min_v"), rec.get("max_v"),
-                rec.get("rw"),
-                rec.get("default_value"),
-                rec.get("current_value"),
-                rec.get("description"),
-            ))
-
-    def list(self, ptype: Optional[str]=None, limit: int=500) -> List[Dict[str, Any]]:
-        with self.db._conn() as c:
-            if ptype:
-                rows = c.execute("""
-                    SELECT ptype,pid,min_v,max_v,rw,default_value,current_value,description
-                    FROM params WHERE ptype=? ORDER BY pid LIMIT ?""", (ptype, limit)).fetchall()
-            else:
-                rows = c.execute("""
-                    SELECT ptype,pid,min_v,max_v,rw,default_value,current_value,description
-                    FROM params ORDER BY ptype,pid LIMIT ?""", (limit,)).fetchall()
-        keys = ["ptype","pid","min_v","max_v","rw","default_value","current_value","description"]
-        return [dict(zip(keys, r)) for r in rows]
-
-    # -------- Excel Import --------
-    def import_xlsx(self, xlsx_path: str) -> Tuple[int, List[str]]:
-        """
-        Erwartete Spalten (entweder per Header oder per Position):
-        A: PARAMS_Type
-        B: PARAM.ID
-        C: Min
-        D: Max
-        E: Default Value
-        F: Description (optional)
-        G: R/W
-        """
-        if not os.path.exists(xlsx_path):
-            return (0, [f"file not found: {xlsx_path}"])
-
-        wb = openpyxl.load_workbook(xlsx_path, data_only=True)
-        ws = wb.active
-
-        # Header erkennen
-        first = [str(v).strip() if v is not None else "" for v in next(ws.iter_rows(min_row=1, max_row=1, values_only=True))]
-        upper = [h.upper() for h in first]
-        has_header = any("TYPE" in h or "PARAM" in h or "R/W" in h for h in upper)
-
-        def pick(row, idx):
-            return row[idx] if idx < len(row) else None
-
-        start_row = 2 if has_header else 1
-
-        count = 0
-        warnings = []
-        for row in ws.iter_rows(min_row=start_row, values_only=True):
-            ptype = pick(row, 0)
-            pid = pick(row, 1)
-            if ptype is None or pid is None:
-                continue
-            ptype = str(ptype).strip().upper()
-            pid = str(pid).strip()
-            # keep leading zeros if excel text; if numeric -> no zeros
-            # (Normalization übernimmt später protocol.normalize_pid beim Matching)
-            min_v = pick(row, 2)
-            max_v = pick(row, 3)
-            default_v = pick(row, 4)
-            desc = pick(row, 5)
-            rw = pick(row, 6)
-
-            rec = {
-                "ptype": ptype,
-                "pid": pid,
-                "min_v": float(min_v) if min_v not in (None, "") else None,
-                "max_v": float(max_v) if max_v not in (None, "") else None,
-                "rw": str(rw).strip().upper() if rw not in (None, "") else None,
-                "default_value": str(default_v).strip() if default_v not in (None, "") else None,
-                "current_value": str(default_v).strip() if default_v not in (None, "") else None,
-                "description": str(desc).strip() if desc not in (None, "") else None,
-            }
-            self.upsert(rec)
-            count += 1
-
-        return (count, warnings)
+import os
+import sqlite3
+from typing import Optional, Dict, Any, List, Tuple
+from contextlib import contextmanager
+import openpyxl
+
+def _colnames(cur, table: str) -> List[str]:
+    rows = cur.execute(f"PRAGMA table_info({table})").fetchall()
+    return [r[1] for r in rows]
+
+class ParamStore:
+    def __init__(self, db):
+        self.db = db
+        self.ensure_schema()
+
+    def ensure_schema(self):
+        with self.db._conn() as c:
+            c.execute("""
+            CREATE TABLE IF NOT EXISTS params(
+              ptype TEXT NOT NULL,
+              pid   TEXT NOT NULL,
+              min_v REAL,
+              max_v REAL,
+              rw    TEXT,
+              default_value TEXT,
+              current_value TEXT,
+              description TEXT,
+              PRIMARY KEY (ptype, pid)
+            )""")
+
+    def get(self, ptype: str, pid: str) -> Optional[Dict[str, Any]]:
+        with self.db._conn() as c:
+            row = c.execute("""
+                SELECT ptype,pid,min_v,max_v,rw,default_value,current_value,description
+                FROM params WHERE ptype=? AND pid=?""", (ptype, pid)).fetchone()
+        if not row:
+            return None
+        keys = ["ptype","pid","min_v","max_v","rw","default_value","current_value","description"]
+        return dict(zip(keys, row))
+
+    def set_current(self, ptype: str, pid: str, value: str):
+        with self.db._conn() as c:
+            c.execute("""
+              UPDATE params SET current_value=? WHERE ptype=? AND pid=?""",
+              (str(value), ptype, pid)
+            )
+
+    def upsert(self, rec: Dict[str, Any]):
+        with self.db._conn() as c:
+            c.execute("""
+              INSERT INTO params(ptype,pid,min_v,max_v,rw,default_value,current_value,description)
+              VALUES(?,?,?,?,?,?,?,?)
+              ON CONFLICT(ptype,pid) DO UPDATE SET
+                min_v=excluded.min_v,
+                max_v=excluded.max_v,
+                rw=excluded.rw,
+                default_value=excluded.default_value,
+                current_value=excluded.current_value,
+                description=excluded.description
+            """, (
+                rec["ptype"], rec["pid"],
+                rec.get("min_v"), rec.get("max_v"),
+                rec.get("rw"),
+                rec.get("default_value"),
+                rec.get("current_value"),
+                rec.get("description"),
+            ))
+
+    def list(self, ptype: Optional[str]=None, limit: int=500) -> List[Dict[str, Any]]:
+        with self.db._conn() as c:
+            if ptype:
+                rows = c.execute("""
+                    SELECT ptype,pid,min_v,max_v,rw,default_value,current_value,description
+                    FROM params WHERE ptype=? ORDER BY pid LIMIT ?""", (ptype, limit)).fetchall()
+            else:
+                rows = c.execute("""
+                    SELECT ptype,pid,min_v,max_v,rw,default_value,current_value,description
+                    FROM params ORDER BY ptype,pid LIMIT ?""", (limit,)).fetchall()
+        keys = ["ptype","pid","min_v","max_v","rw","default_value","current_value","description"]
+        return [dict(zip(keys, r)) for r in rows]
+
+    # -------- Excel Import --------
+    def import_xlsx(self, xlsx_path: str) -> Tuple[int, List[str]]:
+        """
+        Erwartete Spalten (entweder per Header oder per Position):
+        A: PARAMS_Type
+        B: PARAM.ID
+        C: Min
+        D: Max
+        E: Default Value
+        F: Description (optional)
+        G: R/W
+        """
+        if not os.path.exists(xlsx_path):
+            return (0, [f"file not found: {xlsx_path}"])
+
+        wb = openpyxl.load_workbook(xlsx_path, data_only=True)
+        ws = wb.active
+
+        # Header erkennen
+        first = [str(v).strip() if v is not None else "" for v in next(ws.iter_rows(min_row=1, max_row=1, values_only=True))]
+        upper = [h.upper() for h in first]
+        has_header = any("TYPE" in h or "PARAM" in h or "R/W" in h for h in upper)
+
+        def pick(row, idx):
+            return row[idx] if idx < len(row) else None
+
+        start_row = 2 if has_header else 1
+
+        count = 0
+        warnings = []
+        for row in ws.iter_rows(min_row=start_row, values_only=True):
+            ptype = pick(row, 0)
+            pid = pick(row, 1)
+            if ptype is None or pid is None:
+                continue
+            ptype = str(ptype).strip().upper()
+            pid = str(pid).strip()
+            # keep leading zeros if excel text; if numeric -> no zeros
+            # (Normalization übernimmt später protocol.normalize_pid beim Matching)
+            min_v = pick(row, 2)
+            max_v = pick(row, 3)
+            default_v = pick(row, 4)
+            desc = pick(row, 5)
+            rw = pick(row, 6)
+
+            rec = {
+                "ptype": ptype,
+                "pid": pid,
+                "min_v": float(min_v) if min_v not in (None, "") else None,
+                "max_v": float(max_v) if max_v not in (None, "") else None,
+                "rw": str(rw).strip().upper() if rw not in (None, "") else None,
+                "default_value": str(default_v).strip() if default_v not in (None, "") else None,
+                "current_value": str(default_v).strip() if default_v not in (None, "") else None,
+                "description": str(desc).strip() if desc not in (None, "") else None,
+            }
+            self.upsert(rec)
+            count += 1
+
+        return (count, warnings)
diff --git a/mas004_rpi_databridge/protocol.py b/mas004_rpi_databridge/protocol.py
index 7cb8de2..2369472 100644
--- a/mas004_rpi_databridge/protocol.py
+++ b/mas004_rpi_databridge/protocol.py
@@ -1,52 +1,52 @@
-import re
-from dataclasses import dataclass
-from typing import Optional
-
-READONLY_NAK = "NAK_ReadOnly"
-
-@dataclass(frozen=True)
-class ParamMsg:
-    raw: str
-    ptype: Optional[str]   # "TTP"
-    pid: Optional[str]     # "00002"
-    value: Optional[str]   # "50" or "?" or None
-    is_ack: bool = False
-
-_RX = re.compile(r"^(?P<ack>ACK_)?(?P<ptype>[A-Z]{3})(?P<pid>\d+)\s*=\s*(?P<val>.*)$")
-
-_WIDTH = {
-    "TTP": 5,
-    "MAP": 4,
-    "MAS": 4,
-    "TTE": 4, "TTW": 4,
-    "LSE": 4, "LSW": 4,
-    "MAE": 4, "MAW": 4,
-}
-
-def normalize_pid(ptype: str, pid: str) -> str:
-    w = _WIDTH.get(ptype, max(4, len(pid)))
-    # pid kann "2" oder "00002" sein → zfill
-    try:
-        n = int(pid)
-        return str(n).zfill(w)
-    except Exception:
-        return pid.zfill(w)
-
-def parse_param_line(s: str) -> Optional[ParamMsg]:
-    s = (s or "").strip()
-    if not s:
-        return None
-    m = _RX.match(s)
-    if not m:
-        return ParamMsg(raw=s, ptype=None, pid=None, value=s, is_ack=False)  # unknown/raw
-    is_ack = bool(m.group("ack"))
-    ptype = m.group("ptype")
-    pid = normalize_pid(ptype, m.group("pid"))
-    val = (m.group("val") or "").strip()
-    return ParamMsg(raw=s, ptype=ptype, pid=pid, value=val, is_ack=is_ack)
-
-def build_value(ptype: str, pid: str, value: str) -> str:
-    return f"{ptype}{normalize_pid(ptype, pid)}={value}"
-
-def build_ack(ptype: str, pid: str, value: str) -> str:
+import re
+from dataclasses import dataclass
+from typing import Optional
+
+READONLY_NAK = "NAK_ReadOnly"
+
+@dataclass(frozen=True)
+class ParamMsg:
+    raw: str
+    ptype: Optional[str]   # "TTP"
+    pid: Optional[str]     # "00002"
+    value: Optional[str]   # "50" or "?" or None
+    is_ack: bool = False
+
+_RX = re.compile(r"^(?P<ack>ACK_)?(?P<ptype>[A-Z]{3})(?P<pid>\d+)\s*=\s*(?P<val>.*)$")
+
+_WIDTH = {
+    "TTP": 5,
+    "MAP": 4,
+    "MAS": 4,
+    "TTE": 4, "TTW": 4,
+    "LSE": 4, "LSW": 4,
+    "MAE": 4, "MAW": 4,
+}
+
+def normalize_pid(ptype: str, pid: str) -> str:
+    w = _WIDTH.get(ptype, max(4, len(pid)))
+    # pid kann "2" oder "00002" sein → zfill
+    try:
+        n = int(pid)
+        return str(n).zfill(w)
+    except Exception:
+        return pid.zfill(w)
+
+def parse_param_line(s: str) -> Optional[ParamMsg]:
+    s = (s or "").strip()
+    if not s:
+        return None
+    m = _RX.match(s)
+    if not m:
+        return ParamMsg(raw=s, ptype=None, pid=None, value=s, is_ack=False)  # unknown/raw
+    is_ack = bool(m.group("ack"))
+    ptype = m.group("ptype")
+    pid = normalize_pid(ptype, m.group("pid"))
+    val = (m.group("val") or "").strip()
+    return ParamMsg(raw=s, ptype=ptype, pid=pid, value=val, is_ack=is_ack)
+
+def build_value(ptype: str, pid: str, value: str) -> str:
+    return f"{ptype}{normalize_pid(ptype, pid)}={value}"
+
+def build_ack(ptype: str, pid: str, value: str) -> str:
     return f"ACK_{ptype}{normalize_pid(ptype, pid)}={value}"
\ No newline at end of file
diff --git a/mas004_rpi_databridge/readme.txt b/mas004_rpi_databridge/readme.txt
index f45fccb..29dfc4b 100644
--- a/mas004_rpi_databridge/readme.txt
+++ b/mas004_rpi_databridge/readme.txt
@@ -1,23 +1,23 @@
-Config.json mit Token liegt in:
-sudo nano /etc/mas004_rpi_databridge/config.json
-
-Token: siehe /etc/mas004_rpi_databridge/config.json
-
-Raspi Dienst neu starten:
-sudo systemctl restart mas004-rpi-databridge.service
-sudo journalctl -u mas004-rpi-databridge.service -f
-
-URL für Testumgebung:
-http://192.168.1.100:8080/ui/test
-
-URL für Databridge:
-http://192.168.1.100:8080/
-
-URL für Parameterbearbeitung:
-http://192.168.1.100:8080/ui/params
-
-URL für API Doku:
-http://192.168.1.100:8080/docs
-
-Mikrotom Testtool Starten au Power Shell:
-python "D:\Users\Egli_Erwin\Veralto\DE-SMD-Support-Switzerland - Documents\26_VS_CODE\SAR41-MAS-004_Roche_LSR_TTO\Raspberry-PLC\Mikrotom-Simulator\mikrotom_sim.py"
+Config.json mit Token liegt in:
+sudo nano /etc/mas004_rpi_databridge/config.json
+
+Token: siehe /etc/mas004_rpi_databridge/config.json
+
+Raspi Dienst neu starten:
+sudo systemctl restart mas004-rpi-databridge.service
+sudo journalctl -u mas004-rpi-databridge.service -f
+
+URL für Testumgebung:
+http://192.168.1.100:8080/ui/test
+
+URL für Databridge:
+http://192.168.1.100:8080/
+
+URL für Parameterbearbeitung:
+http://192.168.1.100:8080/ui/params
+
+URL für API Doku:
+http://192.168.1.100:8080/docs
+
+Mikrotom Testtool Starten au Power Shell:
+python "D:\Users\Egli_Erwin\Veralto\DE-SMD-Support-Switzerland - Documents\26_VS_CODE\SAR41-MAS-004_Roche_LSR_TTO\Raspberry-PLC\Mikrotom-Simulator\mikrotom_sim.py"
diff --git a/mas004_rpi_databridge/router.py b/mas004_rpi_databridge/router.py
index 14e9133..8c34828 100644
--- a/mas004_rpi_databridge/router.py
+++ b/mas004_rpi_databridge/router.py
@@ -1,144 +1,144 @@
-import json
-import re
-import time
-from typing import Optional, List, Tuple, Dict, Any
-
-from mas004_rpi_databridge.config import Settings
-from mas004_rpi_databridge.inbox import Inbox, InboxMsg
-from mas004_rpi_databridge.outbox import Outbox
-from mas004_rpi_databridge.params import ParamStore
-from mas004_rpi_databridge.logstore import LogStore
-
-READONLY_TYPES = {"TTE", "TTW", "LSE", "LSW", "MAE", "MAW"}  # push-only
-
-def _channel_for_ptype(ptype: str) -> str:
-    ptype = (ptype or "").upper()
-    if ptype.startswith("TT"):   # TTP/TTE/TTW
-        return "tto"
-    if ptype.startswith("LS"):   # LSE/LSW
-        return "laser"
-    if ptype.startswith("MA") or ptype.startswith("MAP") or ptype.startswith("MAS"):
-        return "esp"
-    return "raspi"
-
-def _extract_msg_line(body_json: Optional[str]) -> Optional[str]:
-    if body_json is None:
-        return None
-    try:
-        obj = json.loads(body_json)
-    except Exception:
-        # evtl. plain text
-        s = str(body_json).strip()
-        return s if s else None
-
-    if isinstance(obj, str):
-        return obj.strip() if obj.strip() else None
-    if isinstance(obj, dict):
-        for k in ("msg", "line", "text", "cmd"):
-            v = obj.get(k)
-            if isinstance(v, str) and v.strip():
-                return v.strip()
-        # fallback: JSON als string loggen, aber nicht routen
-        return None
-    return None
-
-def _parse_line(line: str) -> Optional[Tuple[str, str, str, str]]:
-    """
-    Returns (ptype, pid, op, value)
-    op: 'read' (=? / =?) or 'write'
-    """
-    s = (line or "").strip()
-    if not s:
-        return None
-
-    # z.B. "TTP00002=?"
-    m = re.match(r"^\s*([A-Za-z]{3})([0-9A-Za-z_]+)\s*=\s*(\?|-?[0-9A-Za-z_.]+)\s*$", s)
-    if not m:
-        return None
-
-    ptype = m.group(1).upper()
-    pid = m.group(2)
-    rhs = m.group(3)
-    if rhs == "?":
-        return (ptype, pid, "read", "?")
-    return (ptype, pid, "write", rhs)
-
-class Router:
-    def __init__(self, cfg: Settings, inbox: Inbox, outbox: Outbox, params: ParamStore, logs: LogStore):
-        self.cfg = cfg
-        self.inbox = inbox
-        self.outbox = outbox
-        self.params = params
-        self.logs = logs
-
-    def _enqueue_to_mikrotom(self, line: str, correlation: Optional[str] = None):
-        # standardisiert: wir schicken {"msg": "..."} an Mikrotom inbox
-        url = self.cfg.peer_base_url.rstrip("/") + "/api/inbox"
-        headers = {}
-        if correlation:
-            headers["X-Correlation-Id"] = correlation
-        self.outbox.enqueue("POST", url, headers, {"msg": line, "source": "raspi"}, None)
-
-    def handle_mikrotom_line(self, line: str, correlation: Optional[str]) -> Optional[str]:
-        parsed = _parse_line(line)
-        if not parsed:
-            return None
-
-        ptype, pid, op, value = parsed
-        pkey = f"{ptype}{pid}"
-        dev = _channel_for_ptype(ptype)
-
-        # Mikrotom -> Raspi log
-        self.logs.log("raspi", "in", f"mikrotom: {line}")
-        self.logs.log(dev, "in", f"raspi-> {dev}: {line}")
-
-        if op == "read":
-            if ptype in READONLY_TYPES:
-                resp = f"{pkey}=NAK_ReadOnly"
-            else:
-                resp = f"{pkey}={self.params.get_effective_value(pkey)}"
-            # Gerät -> Raspi
-            self.logs.log(dev, "out", f"{dev}->raspi: {resp}")
-            # Raspi -> Mikrotom
-            self.logs.log("raspi", "out", f"to mikrotom: {resp}")
-            self._enqueue_to_mikrotom(resp, correlation=correlation)
-            return resp
-
-        # write
-        if ptype in READONLY_TYPES:
-            resp = f"{pkey}=NAK_ReadOnly"
-            self.logs.log(dev, "out", f"{dev}->raspi: {resp}")
-            self.logs.log("raspi", "out", f"to mikrotom: {resp}")
-            self._enqueue_to_mikrotom(resp, correlation=correlation)
-            return resp
-
-        ok, err = self.params.set_value(pkey, value)
-        if ok:
-            resp = f"ACK_{pkey}={value}"
-        else:
-            resp = f"{pkey}={err}"
-
-        self.logs.log(dev, "out", f"{dev}->raspi: {resp}")
-        self.logs.log("raspi", "out", f"to mikrotom: {resp}")
-        self._enqueue_to_mikrotom(resp, correlation=correlation)
-        return resp
-
-    def tick_once(self) -> bool:
-        msg = self.inbox.claim_next_pending()
-        if not msg:
-            return False
-
-        line = _extract_msg_line(msg.body_json)
-        if not line:
-            self.logs.log("raspi", "info", f"mikrotom msg id={msg.id} ohne 'msg/line/text/cmd' -> ignoriert")
-            self.inbox.ack(msg.id)
-            return True
-
-        try:
-            self.handle_mikrotom_line(line, correlation=msg.idempotency_key)
-        except Exception as e:
-            self.logs.log("raspi", "error", f"router error for inbox id={msg.id}: {repr(e)}")
-        finally:
-            self.inbox.ack(msg.id)
-
-        return True
+import json
+import re
+import time
+from typing import Optional, List, Tuple, Dict, Any
+
+from mas004_rpi_databridge.config import Settings
+from mas004_rpi_databridge.inbox import Inbox, InboxMsg
+from mas004_rpi_databridge.outbox import Outbox
+from mas004_rpi_databridge.params import ParamStore
+from mas004_rpi_databridge.logstore import LogStore
+
+READONLY_TYPES = {"TTE", "TTW", "LSE", "LSW", "MAE", "MAW"}  # push-only
+
+def _channel_for_ptype(ptype: str) -> str:
+    ptype = (ptype or "").upper()
+    if ptype.startswith("TT"):   # TTP/TTE/TTW
+        return "tto"
+    if ptype.startswith("LS"):   # LSE/LSW
+        return "laser"
+    if ptype.startswith("MA") or ptype.startswith("MAP") or ptype.startswith("MAS"):
+        return "esp"
+    return "raspi"
+
+def _extract_msg_line(body_json: Optional[str]) -> Optional[str]:
+    if body_json is None:
+        return None
+    try:
+        obj = json.loads(body_json)
+    except Exception:
+        # evtl. plain text
+        s = str(body_json).strip()
+        return s if s else None
+
+    if isinstance(obj, str):
+        return obj.strip() if obj.strip() else None
+    if isinstance(obj, dict):
+        for k in ("msg", "line", "text", "cmd"):
+            v = obj.get(k)
+            if isinstance(v, str) and v.strip():
+                return v.strip()
+        # fallback: JSON als string loggen, aber nicht routen
+        return None
+    return None
+
+def _parse_line(line: str) -> Optional[Tuple[str, str, str, str]]:
+    """
+    Returns (ptype, pid, op, value)
+    op: 'read' (=? / =?) or 'write'
+    """
+    s = (line or "").strip()
+    if not s:
+        return None
+
+    # z.B. "TTP00002=?"
+    m = re.match(r"^\s*([A-Za-z]{3})([0-9A-Za-z_]+)\s*=\s*(\?|-?[0-9A-Za-z_.]+)\s*$", s)
+    if not m:
+        return None
+
+    ptype = m.group(1).upper()
+    pid = m.group(2)
+    rhs = m.group(3)
+    if rhs == "?":
+        return (ptype, pid, "read", "?")
+    return (ptype, pid, "write", rhs)
+
+class Router:
+    def __init__(self, cfg: Settings, inbox: Inbox, outbox: Outbox, params: ParamStore, logs: LogStore):
+        self.cfg = cfg
+        self.inbox = inbox
+        self.outbox = outbox
+        self.params = params
+        self.logs = logs
+
+    def _enqueue_to_mikrotom(self, line: str, correlation: Optional[str] = None):
+        # standardisiert: wir schicken {"msg": "..."} an Mikrotom inbox
+        url = self.cfg.peer_base_url.rstrip("/") + "/api/inbox"
+        headers = {}
+        if correlation:
+            headers["X-Correlation-Id"] = correlation
+        self.outbox.enqueue("POST", url, headers, {"msg": line, "source": "raspi"}, None)
+
+    def handle_mikrotom_line(self, line: str, correlation: Optional[str]) -> Optional[str]:
+        parsed = _parse_line(line)
+        if not parsed:
+            return None
+
+        ptype, pid, op, value = parsed
+        pkey = f"{ptype}{pid}"
+        dev = _channel_for_ptype(ptype)
+
+        # Mikrotom -> Raspi log
+        self.logs.log("raspi", "in", f"mikrotom: {line}")
+        self.logs.log(dev, "in", f"raspi-> {dev}: {line}")
+
+        if op == "read":
+            if ptype in READONLY_TYPES:
+                resp = f"{pkey}=NAK_ReadOnly"
+            else:
+                resp = f"{pkey}={self.params.get_effective_value(pkey)}"
+            # Gerät -> Raspi
+            self.logs.log(dev, "out", f"{dev}->raspi: {resp}")
+            # Raspi -> Mikrotom
+            self.logs.log("raspi", "out", f"to mikrotom: {resp}")
+            self._enqueue_to_mikrotom(resp, correlation=correlation)
+            return resp
+
+        # write
+        if ptype in READONLY_TYPES:
+            resp = f"{pkey}=NAK_ReadOnly"
+            self.logs.log(dev, "out", f"{dev}->raspi: {resp}")
+            self.logs.log("raspi", "out", f"to mikrotom: {resp}")
+            self._enqueue_to_mikrotom(resp, correlation=correlation)
+            return resp
+
+        ok, err = self.params.set_value(pkey, value)
+        if ok:
+            resp = f"ACK_{pkey}={value}"
+        else:
+            resp = f"{pkey}={err}"
+
+        self.logs.log(dev, "out", f"{dev}->raspi: {resp}")
+        self.logs.log("raspi", "out", f"to mikrotom: {resp}")
+        self._enqueue_to_mikrotom(resp, correlation=correlation)
+        return resp
+
+    def tick_once(self) -> bool:
+        msg = self.inbox.claim_next_pending()
+        if not msg:
+            return False
+
+        line = _extract_msg_line(msg.body_json)
+        if not line:
+            self.logs.log("raspi", "info", f"mikrotom msg id={msg.id} ohne 'msg/line/text/cmd' -> ignoriert")
+            self.inbox.ack(msg.id)
+            return True
+
+        try:
+            self.handle_mikrotom_line(line, correlation=msg.idempotency_key)
+        except Exception as e:
+            self.logs.log("raspi", "error", f"router error for inbox id={msg.id}: {repr(e)}")
+        finally:
+            self.inbox.ack(msg.id)
+
+        return True
diff --git a/mas004_rpi_databridge/service.py b/mas004_rpi_databridge/service.py
index d9f496b..bb6f996 100644
--- a/mas004_rpi_databridge/service.py
+++ b/mas004_rpi_databridge/service.py
@@ -1,87 +1,87 @@
-import time
-import threading
-import json
-import os
-import uvicorn
-
-from mas004_rpi_databridge.config import Settings, DEFAULT_CFG_PATH
-from mas004_rpi_databridge.db import DB
-from mas004_rpi_databridge.outbox import Outbox
-from mas004_rpi_databridge.http_client import HttpClient
-from mas004_rpi_databridge.watchdog import Watchdog
-from mas004_rpi_databridge.webui import build_app
-
-def backoff_s(retry_count: int, base: float, cap: float) -> float:
-    n = min(retry_count, 10)
-    return min(cap, base * (2 ** n))
-
-def sender_loop(cfg_path: str):
-    while True:
-        cfg = Settings.load(cfg_path)
-        db = DB(cfg.db_path)
-        outbox = Outbox(db)
-
-        health_url = None
-        if cfg.peer_health_path:
-            health_url = cfg.peer_base_url.rstrip("/") + cfg.peer_health_path
-
-        watchdog = Watchdog(
-            host=cfg.peer_watchdog_host,
-            interval_s=cfg.watchdog_interval_s,
-            timeout_s=cfg.watchdog_timeout_s,
-            down_after=cfg.watchdog_down_after,
-            health_url=health_url,
-            tls_verify=cfg.tls_verify
-        )
-
-        client = HttpClient(timeout_s=cfg.http_timeout_s, source_ip=cfg.eth0_source_ip, verify_tls=cfg.tls_verify)
-
-        while True:
-            up = watchdog.tick()
-            if not up:
-                time.sleep(cfg.watchdog_interval_s)
-                continue
-
-            job = outbox.next_due()
-            if not job:
-                time.sleep(0.2)
-                continue
-
-            try:
-                headers = json.loads(job.headers_json)
-                body = json.loads(job.body_json) if job.body_json else None
-
-                print(f"[OUTBOX] send id={job.id} rc={job.retry_count} {job.method} {job.url}", flush=True)
-                resp = client.request(job.method, job.url, headers, body)
-                print(f"[OUTBOX] ok   id={job.id} resp={resp}", flush=True)
-
-                outbox.delete(job.id)
-
-            except Exception as e:
-                rc = job.retry_count + 1
-                next_ts = time.time() + backoff_s(rc, cfg.retry_base_s, cfg.retry_cap_s)
-                print(f"[OUTBOX] FAIL id={job.id} rc={rc} next_in={int(next_ts-time.time())}s err={repr(e)}", flush=True)
-                outbox.reschedule(job.id, rc, next_ts)
-
-def main():
-    cfg_path = DEFAULT_CFG_PATH
-    cfg = Settings.load(cfg_path)
-
-    t = threading.Thread(target=sender_loop, args=(cfg_path,), daemon=True)
-    t.start()
-
-    app = build_app(cfg_path)
-
-    ssl_kwargs = {}
-    if cfg.webui_https:
-        # Nur aktivieren, wenn Dateien existieren – sonst klare Fehlermeldung
-        if not (os.path.exists(cfg.webui_ssl_certfile) and os.path.exists(cfg.webui_ssl_keyfile)):
-            raise RuntimeError(
-                f"HTTPS aktiviert, aber Zertifikat/Key fehlt: cert={cfg.webui_ssl_certfile} key={cfg.webui_ssl_keyfile}"
-            )
-        ssl_kwargs = {
-            "ssl_certfile": cfg.webui_ssl_certfile,
-            "ssl_keyfile": cfg.webui_ssl_keyfile,
-        }
-
-    uvicorn.run(app, host=cfg.webui_host, port=cfg.webui_port, log_level="info", **ssl_kwargs)
+import time
+import threading
+import json
+import os
+import uvicorn
+
+from mas004_rpi_databridge.config import Settings, DEFAULT_CFG_PATH
+from mas004_rpi_databridge.db import DB
+from mas004_rpi_databridge.outbox import Outbox
+from mas004_rpi_databridge.http_client import HttpClient
+from mas004_rpi_databridge.watchdog import Watchdog
+from mas004_rpi_databridge.webui import build_app
+
+def backoff_s(retry_count: int, base: float, cap: float) -> float:
+    n = min(retry_count, 10)
+    return min(cap, base * (2 ** n))
+
+def sender_loop(cfg_path: str):
+    while True:
+        cfg = Settings.load(cfg_path)
+        db = DB(cfg.db_path)
+        outbox = Outbox(db)
+
+        health_url = None
+        if cfg.peer_health_path:
+            health_url = cfg.peer_base_url.rstrip("/") + cfg.peer_health_path
+
+        watchdog = Watchdog(
+            host=cfg.peer_watchdog_host,
+            interval_s=cfg.watchdog_interval_s,
+            timeout_s=cfg.watchdog_timeout_s,
+            down_after=cfg.watchdog_down_after,
+            health_url=health_url,
+            tls_verify=cfg.tls_verify
+        )
+
+        client = HttpClient(timeout_s=cfg.http_timeout_s, source_ip=cfg.eth0_source_ip, verify_tls=cfg.tls_verify)
+
+        while True:
+            up = watchdog.tick()
+            if not up:
+                time.sleep(cfg.watchdog_interval_s)
+                continue
+
+            job = outbox.next_due()
+            if not job:
+                time.sleep(0.2)
+                continue
+
+            try:
+                headers = json.loads(job.headers_json)
+                body = json.loads(job.body_json) if job.body_json else None
+
+                print(f"[OUTBOX] send id={job.id} rc={job.retry_count} {job.method} {job.url}", flush=True)
+                resp = client.request(job.method, job.url, headers, body)
+                print(f"[OUTBOX] ok   id={job.id} resp={resp}", flush=True)
+
+                outbox.delete(job.id)
+
+            except Exception as e:
+                rc = job.retry_count + 1
+                next_ts = time.time() + backoff_s(rc, cfg.retry_base_s, cfg.retry_cap_s)
+                print(f"[OUTBOX] FAIL id={job.id} rc={rc} next_in={int(next_ts-time.time())}s err={repr(e)}", flush=True)
+                outbox.reschedule(job.id, rc, next_ts)
+
+def main():
+    cfg_path = DEFAULT_CFG_PATH
+    cfg = Settings.load(cfg_path)
+
+    t = threading.Thread(target=sender_loop, args=(cfg_path,), daemon=True)
+    t.start()
+
+    app = build_app(cfg_path)
+
+    ssl_kwargs = {}
+    if cfg.webui_https:
+        # Nur aktivieren, wenn Dateien existieren – sonst klare Fehlermeldung
+        if not (os.path.exists(cfg.webui_ssl_certfile) and os.path.exists(cfg.webui_ssl_keyfile)):
+            raise RuntimeError(
+                f"HTTPS aktiviert, aber Zertifikat/Key fehlt: cert={cfg.webui_ssl_certfile} key={cfg.webui_ssl_keyfile}"
+            )
+        ssl_kwargs = {
+            "ssl_certfile": cfg.webui_ssl_certfile,
+            "ssl_keyfile": cfg.webui_ssl_keyfile,
+        }
+
+    uvicorn.run(app, host=cfg.webui_host, port=cfg.webui_port, log_level="info", **ssl_kwargs)
diff --git a/mas004_rpi_databridge/watchdog.py b/mas004_rpi_databridge/watchdog.py
index 2cd2541..946d9b9 100644
--- a/mas004_rpi_databridge/watchdog.py
+++ b/mas004_rpi_databridge/watchdog.py
@@ -1,65 +1,65 @@
-# mas004_rpi_databridge/watchdog.py
-import time
-from typing import Optional
-
-from ping3 import ping
-import httpx
-
-
-class Watchdog:
-    def __init__(
-        self,
-        host: str,
-        interval_s: float,
-        timeout_s: float,
-        down_after: int,
-        health_url: Optional[str] = None,
-        tls_verify: bool = True,
-    ):
-        self.host = host
-        self.interval_s = float(interval_s)
-        self.timeout_s = float(timeout_s)
-        self.down_after = int(down_after)
-        self.health_url = health_url
-        self.tls_verify = bool(tls_verify)
-
-        self._fail = 0
-        self.is_up = True
-
-        # Rate limit: nur alle interval_s wirklich prüfen
-        self._next_check_ts = 0.0  # 0 => beim ersten tick() sofort prüfen
-
-    def tick(self) -> bool:
-        now = time.time()
-
-        # Wenn wir zu früh dran sind: alten Status zurückgeben, keine neuen Requests
-        if now < self._next_check_ts:
-            return self.is_up
-
-        # Nächster erlaubter Check-Zeitpunkt
-        self._next_check_ts = now + self.interval_s
-
-        ok = self._ping_ok()
-        if ok and self.health_url:
-            ok = self._health_ok()
-
-        self._fail = 0 if ok else (self._fail + 1)
-        self.is_up = (self._fail < self.down_after)
-        return self.is_up
-
-    def _ping_ok(self) -> bool:
-        try:
-            # ping() gibt None bei Timeout zurück
-            return ping(self.host, timeout=self.timeout_s, unit="ms") is not None
-        except Exception:
-            return False
-
-    def _health_ok(self) -> bool:
-        if not self.health_url:
-            return True
-        try:
-            with httpx.Client(timeout=self.timeout_s, verify=self.tls_verify) as c:
-                r = c.get(self.health_url)
-                return 200 <= r.status_code < 300
-        except Exception:
-            return False
+# mas004_rpi_databridge/watchdog.py
+import time
+from typing import Optional
+
+from ping3 import ping
+import httpx
+
+
+class Watchdog:
+    def __init__(
+        self,
+        host: str,
+        interval_s: float,
+        timeout_s: float,
+        down_after: int,
+        health_url: Optional[str] = None,
+        tls_verify: bool = True,
+    ):
+        self.host = host
+        self.interval_s = float(interval_s)
+        self.timeout_s = float(timeout_s)
+        self.down_after = int(down_after)
+        self.health_url = health_url
+        self.tls_verify = bool(tls_verify)
+
+        self._fail = 0
+        self.is_up = True
+
+        # Rate limit: nur alle interval_s wirklich prüfen
+        self._next_check_ts = 0.0  # 0 => beim ersten tick() sofort prüfen
+
+    def tick(self) -> bool:
+        now = time.time()
+
+        # Wenn wir zu früh dran sind: alten Status zurückgeben, keine neuen Requests
+        if now < self._next_check_ts:
+            return self.is_up
+
+        # Nächster erlaubter Check-Zeitpunkt
+        self._next_check_ts = now + self.interval_s
+
+        ok = self._ping_ok()
+        if ok and self.health_url:
+            ok = self._health_ok()
+
+        self._fail = 0 if ok else (self._fail + 1)
+        self.is_up = (self._fail < self.down_after)
+        return self.is_up
+
+    def _ping_ok(self) -> bool:
+        try:
+            # ping() gibt None bei Timeout zurück
+            return ping(self.host, timeout=self.timeout_s, unit="ms") is not None
+        except Exception:
+            return False
+
+    def _health_ok(self) -> bool:
+        if not self.health_url:
+            return True
+        try:
+            with httpx.Client(timeout=self.timeout_s, verify=self.tls_verify) as c:
+                r = c.get(self.health_url)
+                return 200 <= r.status_code < 300
+        except Exception:
+            return False
diff --git a/mas004_rpi_databridge/webui.py b/mas004_rpi_databridge/webui.py
index 7c8dcdf..d64b3fe 100644
--- a/mas004_rpi_databridge/webui.py
+++ b/mas004_rpi_databridge/webui.py
@@ -337,7 +337,9 @@ def build_app(cfg_path: str = DEFAULT_CFG_PATH) -> FastAPI:
     def log_channels(x_token: Optional[str] = Header(default=None)):
         cfg2 = Settings.load(cfg_path)
         require_token(x_token, cfg2)
-        return {"ok": True, "channels": logs.list_channels()}
+        default = ['raspi','esp-plc','vj3350','vj6530']
+        ch = list(dict.fromkeys(default + (logs.list_channels() or [])))
+        return {'ok': True, 'channels': ch}
 
     @app.get("/api/ui/logs")
     def get_logs(
@@ -564,17 +566,116 @@ load();
   <meta charset="utf-8"/>
   <title>System Settings</title>
   <style>
-    body{font-family:Arial; margin:20px; max-width:1100px}
-    .row{display:flex; gap:10px; align-items:center; flex-wrap:wrap}
-    input{padding:6px; margin:4px}
-    button{padding:7px 10px; cursor:pointer}
-    fieldset{border:1px solid #ddd; margin:12px 0; padding:12px; border-radius:8px}
-    legend{padding:0 6px; color:#333}
-    pre{background:#111; color:#eee; padding:10px; border-radius:10px; overflow:auto; max-height:260px}
-    .muted{color:#666}
-    .pill{padding:2px 6px; border:1px solid #aaa; border-radius:10px; font-size:12px}
-    .bad{outline:2px solid #b00}
-  </style>
+
+  :root{
+    --vj-navy:#003A70;
+    --vj-blue:#005EB8;
+    --vj-red:#E4002B;
+    --bg:#F5F7FA;
+    --card:#FFFFFF;
+    --text:#1D232B;
+    --muted:#5F6B7A;
+    --border:#D8E0EA;
+    --radius:14px;
+    --shadow:0 6px 24px rgba(0,0,0,.08);
+  }
+  html,body{height:100%;}
+  body{
+    margin:0;
+    font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif;
+    background:var(--bg);
+    color:var(--text);
+  }
+  header{
+    background:linear-gradient(90deg,var(--vj-navy),var(--vj-blue));
+    color:#fff;
+    padding:14px 18px;
+    box-shadow:0 2px 14px rgba(0,0,0,.15);
+    position:sticky;
+    top:0;
+    z-index:10;
+  }
+  header .row{
+    display:flex;
+    align-items:center;
+    gap:14px;
+    justify-content:space-between;
+    flex-wrap:wrap;
+  }
+  .brand{
+    display:flex;
+    align-items:center;
+    gap:12px;
+  }
+  .badge{
+    font-size:12px;
+    padding:4px 8px;
+    border:1px solid rgba(255,255,255,.35);
+    border-radius:999px;
+    opacity:.95;
+  }
+  main{padding:18px; max-width:1200px; margin:0 auto;}
+  .grid{
+    display:grid;
+    grid-template-columns:repeat(12,1fr);
+    gap:14px;
+  }
+  .card{
+    grid-column:span 12;
+    background:var(--card);
+    border:1px solid var(--border);
+    border-radius:var(--radius);
+    box-shadow:var(--shadow);
+    padding:16px;
+  }
+  .card h2{margin:0 0 10px 0; font-size:18px;}
+  .sub{color:var(--muted); font-size:13px; margin-top:2px;}
+  .row{display:flex; gap:10px; flex-wrap:wrap; align-items:center;}
+  label{font-size:12px; color:var(--muted);}
+  input,select,textarea{
+    width:100%;
+    padding:10px 12px;
+    border:1px solid var(--border);
+    border-radius:12px;
+    background:#fff;
+    font-size:14px;
+    outline:none;
+  }
+  textarea{min-height:110px; font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;}
+  input:focus,select:focus,textarea:focus{border-color:var(--vj-blue); box-shadow:0 0 0 3px rgba(0,94,184,.15);}
+  .btn{
+    appearance:none;
+    border:0;
+    cursor:pointer;
+    padding:10px 14px;
+    border-radius:12px;
+    font-weight:600;
+    font-size:14px;
+  }
+  .btn.primary{background:var(--vj-blue); color:#fff;}
+  .btn.danger{background:var(--vj-red); color:#fff;}
+  .btn.ghost{background:#fff; border:1px solid rgba(255,255,255,.45); color:#fff;}
+  .btn:active{transform:translateY(1px);}
+  .pill{
+    display:inline-flex;
+    align-items:center;
+    gap:8px;
+    padding:8px 10px;
+    border:1px solid var(--border);
+    border-radius:999px;
+    font-size:13px;
+    background:#fff;
+  }
+  .ok{color:#0B7A3B; font-weight:700;}
+  .bad{color:var(--vj-red); font-weight:700;}
+  .mono{font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;}
+  .split{display:grid; grid-template-columns:repeat(12,1fr); gap:12px;}
+  .col6{grid-column:span 6;}
+  .col4{grid-column:span 4;}
+  .col8{grid-column:span 8;}
+  @media(max-width:900px){.col6,.col4,.col8{grid-column:span 12;}}
+
+</style>
 </head>
 <body>
   <h2>System Settings</h2>
@@ -885,16 +986,119 @@ reloadAll();
   <meta charset="utf-8"/>
   <title>MAS-004 Test UI</title>
   <style>
-    body{font-family:Arial; margin:20px; max-width:1100px}
-    .row{display:flex; gap:10px; align-items:center; flex-wrap:wrap}
-    input{padding:6px; margin:4px}
-    button{padding:7px 10px; cursor:pointer}
-    .tabs button{border:1px solid #aaa; border-radius:10px; background:#f3f3f3}
-    .tabs button.active{background:#ddd}
-    pre{background:#111; color:#eee; padding:10px; border-radius:10px; overflow:auto; max-height:420px}
-    .muted{color:#666}
-    select{padding:6px}
-  </style>
+
+  :root{
+    --vj-navy:#003A70;
+    --vj-blue:#005EB8;
+    --vj-red:#E4002B;
+    --bg:#F5F7FA;
+    --card:#FFFFFF;
+    --text:#1D232B;
+    --muted:#5F6B7A;
+    --border:#D8E0EA;
+    --radius:14px;
+    --shadow:0 6px 24px rgba(0,0,0,.08);
+  }
+  html,body{height:100%;}
+  body{
+    margin:0;
+    font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif;
+    background:var(--bg);
+    color:var(--text);
+  }
+  header{
+    background:linear-gradient(90deg,var(--vj-navy),var(--vj-blue));
+    color:#fff;
+    padding:14px 18px;
+    box-shadow:0 2px 14px rgba(0,0,0,.15);
+    position:sticky;
+    top:0;
+    z-index:10;
+  }
+  header .row{
+    display:flex;
+    align-items:center;
+    gap:14px;
+    justify-content:space-between;
+    flex-wrap:wrap;
+  }
+  .brand{
+    display:flex;
+    align-items:center;
+    gap:12px;
+  }
+  .badge{
+    font-size:12px;
+    padding:4px 8px;
+    border:1px solid rgba(255,255,255,.35);
+    border-radius:999px;
+    opacity:.95;
+  }
+  main{padding:18px; max-width:1200px; margin:0 auto;}
+  .grid{
+    display:grid;
+    grid-template-columns:repeat(12,1fr);
+    gap:14px;
+  }
+  .card{
+    grid-column:span 12;
+    background:var(--card);
+    border:1px solid var(--border);
+    border-radius:var(--radius);
+    box-shadow:var(--shadow);
+    padding:16px;
+  }
+  .card h2{margin:0 0 10px 0; font-size:18px;}
+  .sub{color:var(--muted); font-size:13px; margin-top:2px;}
+  .row{display:flex; gap:10px; flex-wrap:wrap; align-items:center;}
+  label{font-size:12px; color:var(--muted);}
+  input,select,textarea{
+    width:100%;
+    padding:10px 12px;
+    border:1px solid var(--border);
+    border-radius:12px;
+    background:#fff;
+    font-size:14px;
+    outline:none;
+  }
+  textarea{min-height:110px; font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;}
+  input:focus,select:focus,textarea:focus{border-color:var(--vj-blue); box-shadow:0 0 0 3px rgba(0,94,184,.15);}
+  .btn{
+    appearance:none;
+    border:0;
+    cursor:pointer;
+    padding:10px 14px;
+    border-radius:12px;
+    font-weight:600;
+    font-size:14px;
+  }
+  .btn.primary{background:var(--vj-blue); color:#fff;}
+  .btn.danger{background:var(--vj-red); color:#fff;}
+  .btn.ghost{background:#fff; border:1px solid rgba(255,255,255,.45); color:#fff;}
+  .btn:active{transform:translateY(1px);}
+  .pill{
+    display:inline-flex;
+    align-items:center;
+    gap:8px;
+    padding:8px 10px;
+    border:1px solid var(--border);
+    border-radius:999px;
+    font-size:13px;
+    background:#fff;
+  }
+  .ok{color:#0B7A3B; font-weight:700;}
+  .bad{color:var(--vj-red); font-weight:700;}
+  .mono{font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;}
+  .split{display:grid; grid-template-columns:repeat(12,1fr); gap:12px;}
+  .col6{grid-column:span 6;}
+  .col4{grid-column:span 4;}
+  .col8{grid-column:span 8;}
+  @media(max-width:900px){.col6,.col4,.col8{grid-column:span 12;}}
+
+  pre{white-space:pre-wrap; margin:0;}
+  .logs{max-height:420px; overflow:auto;}
+
+</style>
 </head>
 <body>
   <h2>MAS-004 Test UI</h2>
@@ -1041,4 +1245,4 @@ loadChannels().then(loadLogs);
 </body></html>
         """
 
-    return app
\ No newline at end of file
+    return app
diff --git a/mas004_rpi_databridge/webui.py.save b/mas004_rpi_databridge/webui.py.save
index 5c3aca9..5fbc44e 100644
--- a/mas004_rpi_databridge/webui.py.save
+++ b/mas004_rpi_databridge/webui.py.save
@@ -1,140 +1,140 @@
-from typing import Optional, Dict, Any
-
-from fastapi import FastAPI, Request, HTTPException, Header
-from fastapi.responses import HTMLResponse
-from pydantic import BaseModel
-import subprocess
-
-from mas004_rpi_databridge.config import Settings, DEFAULT_CFG_PATH
-from mas004_rpi_databridge.db import DB
-from mas004_rpi_databridge.outbox import Outbox
-from mas004_rpi_databridge.inbox import Inbox
-
-
-def require_token(x_token: Optional[str], cfg: Settings):
-    if cfg.ui_token and x_token != cfg.ui_token:
-        raise HTTPException(status_code=401, detail="Unauthorized")
-
-
-class ConfigUpdate(BaseModel):
-    peer_base_url: Optional[str] = None
-    peer_watchdog_host: Optional[str] = None
-    peer_health_path: Optional[str] = None
-    tls_verify: Optional[bool] = None
-    http_timeout_s: Optional[float] = None
-    eth0_source_ip: Optional[str] = None
-    webui_port: Optional[int] = None
-    ui_token: Optional[str] = None
-
-
-class OutboxEnqueue(BaseModel):
-    method: str = "POST"
-    path: str = "/api/inbox"
-    url: Optional[str] = None
-    headers: Dict[str, Any] = {}
-    body: Optional[Dict[str, Any]] = None
-    idempotency_key: Optional[str] = None
-
-
-def build_app(cfg_path: str = DEFAULT_CFG_PATH) -> FastAPI:
-    app = FastAPI(title="MAS-004_RPI-Databridge", version="0.1.0")
-
-    cfg = Settings.load(cfg_path)
-    db = DB(cfg.db_path)
-    outbox = Outbox(db)
-    inbox = Inbox(db)
-
-    @app.get("/", response_class=HTMLResponse)
-    def home():
-        cfg2 = Settings.load(cfg_path)
-        return f"""
-        <html><body style="font-family:Arial;max-width:900px;margin:20px">
-        <h2>MAS-004_RPI-Databridge</h2>
-        <p><b>eth0:</b> {cfg2.eth0_ip} | <b>eth1:</b> {cfg2.eth1_ip}</p>
-        <p><b>Outbox:</b> {outbox.count()} | <b>Inbox pending:</b> {inbox.count_pending()}</p>
-        <p><b>Peer:</b> {cfg2.peer_base_url} | Watchdog: {cfg2.peer_watchdog_host}</p>
-        <p>Docs: <a href="/docs">/docs</a></p>
-        </body></html>
-        """
-
-    @app.get("/health")
-    def health():
-        return {"ok": True}
-
-    @app.get("/api/config")
-    def get_config():
-        cfg2 = Settings.load(cfg_path)
-        d = cfg2.__dict__.copy()
-        d["ui_token"] = "***"
-        return d
-
-    @app.post("/api/config")
-    def update_config(u: ConfigUpdate, x_token: Optional[str] = Header(default=None)):
-        cfg2 = Settings.load(cfg_path)
-        require_token(x_token, cfg2)
-
-        for k, v in u.model_dump().items():
-            if v is not None:
-                setattr(cfg2, k, v)
-
-        cfg2.save(cfg_path)
-        subprocess.call(["bash", "-lc", "systemctl restart mas004-rpi-databridge.service"])
-        return {"ok": True}
-
-    @app.post("/api/outbox/enqueue")
-    def api_outbox_enqueue(req: OutboxEnqueue, x_token: Optional[str] = Header(default=None)):
-        cfg2 = Settings.load(cfg_path)
-        require_token(x_token, cfg2)
-
-        url = req.url if req.url else cfg2.peer_base_url.rstrip("/") + req.path
-        idem = outbox.enqueue(req.method, url, req.headers, req.body, req.idempotency_key)
-        return {"ok": True, "idempotency_key": idem}
-
-    @app.post("/api/inbox")
-    async def api_inbox(request: Request, x_idempotency_key: Optional[str] = Header(default=None)):
-        body = None
-        cfg2 = Settings.load(cfg_path)
-        if cfg2.shared_secret and x_shared_secret != cfg2.shared_secret:
-            raise HTTPException(status_code=401, detail="Unauthorized")        cfg2 = Settings.load(cfg_path)
-        if cfg2.shared_secret and x_shared_secret != cfg2.shared_secret:
-            raise HTTPException(status_code=401, detail="Unauthorized")
-        try:
-            body = await request.json()
-        except Exception:
-            body = None
-
-        headers = dict(request.headers)
-        idem = x_idempotency_key or headers.get("x-idempotency-key") or "missing"
-        source = request.client.host if request.client else None
-        inserted = inbox.store(source, headers, body, idem)
-        return {"ok": True, "stored": inserted, "idempotency_key": idem}
-
-    @app.get("/api/inbox/next")
-    def api_inbox_next(x_token: Optional[str] = Header(default=None)):
-        cfg2 = Settings.load(cfg_path)
-        require_token(x_token, cfg2)
-
-        msg = inbox.next_pending()
-        if not msg:
-            return {"ok": True, "msg": None}
-
-        return {
-            "ok": True,
-            "msg": {
-                "id": msg.id,
-                "received_ts": msg.received_ts,
-                "source": msg.source,
-                "headers_json": msg.headers_json,
-                "body_json": msg.body_json,
-                "idempotency_key": msg.idempotency_key,
-            },
-        }
-
-    @app.post("/api/inbox/{msg_id}/ack")
-    def api_inbox_ack(msg_id: int, x_token: Optional[str] = Header(default=None)):
-        cfg2 = Settings.load(cfg_path)
-        require_token(x_token, cfg2)
-        inbox.ack(msg_id)
-        return {"ok": True}
-
-    return app
+from typing import Optional, Dict, Any
+
+from fastapi import FastAPI, Request, HTTPException, Header
+from fastapi.responses import HTMLResponse
+from pydantic import BaseModel
+import subprocess
+
+from mas004_rpi_databridge.config import Settings, DEFAULT_CFG_PATH
+from mas004_rpi_databridge.db import DB
+from mas004_rpi_databridge.outbox import Outbox
+from mas004_rpi_databridge.inbox import Inbox
+
+
+def require_token(x_token: Optional[str], cfg: Settings):
+    if cfg.ui_token and x_token != cfg.ui_token:
+        raise HTTPException(status_code=401, detail="Unauthorized")
+
+
+class ConfigUpdate(BaseModel):
+    peer_base_url: Optional[str] = None
+    peer_watchdog_host: Optional[str] = None
+    peer_health_path: Optional[str] = None
+    tls_verify: Optional[bool] = None
+    http_timeout_s: Optional[float] = None
+    eth0_source_ip: Optional[str] = None
+    webui_port: Optional[int] = None
+    ui_token: Optional[str] = None
+
+
+class OutboxEnqueue(BaseModel):
+    method: str = "POST"
+    path: str = "/api/inbox"
+    url: Optional[str] = None
+    headers: Dict[str, Any] = {}
+    body: Optional[Dict[str, Any]] = None
+    idempotency_key: Optional[str] = None
+
+
+def build_app(cfg_path: str = DEFAULT_CFG_PATH) -> FastAPI:
+    app = FastAPI(title="MAS-004_RPI-Databridge", version="0.1.0")
+
+    cfg = Settings.load(cfg_path)
+    db = DB(cfg.db_path)
+    outbox = Outbox(db)
+    inbox = Inbox(db)
+
+    @app.get("/", response_class=HTMLResponse)
+    def home():
+        cfg2 = Settings.load(cfg_path)
+        return f"""
+        <html><body style="font-family:Arial;max-width:900px;margin:20px">
+        <h2>MAS-004_RPI-Databridge</h2>
+        <p><b>eth0:</b> {cfg2.eth0_ip} | <b>eth1:</b> {cfg2.eth1_ip}</p>
+        <p><b>Outbox:</b> {outbox.count()} | <b>Inbox pending:</b> {inbox.count_pending()}</p>
+        <p><b>Peer:</b> {cfg2.peer_base_url} | Watchdog: {cfg2.peer_watchdog_host}</p>
+        <p>Docs: <a href="/docs">/docs</a></p>
+        </body></html>
+        """
+
+    @app.get("/health")
+    def health():
+        return {"ok": True}
+
+    @app.get("/api/config")
+    def get_config():
+        cfg2 = Settings.load(cfg_path)
+        d = cfg2.__dict__.copy()
+        d["ui_token"] = "***"
+        return d
+
+    @app.post("/api/config")
+    def update_config(u: ConfigUpdate, x_token: Optional[str] = Header(default=None)):
+        cfg2 = Settings.load(cfg_path)
+        require_token(x_token, cfg2)
+
+        for k, v in u.model_dump().items():
+            if v is not None:
+                setattr(cfg2, k, v)
+
+        cfg2.save(cfg_path)
+        subprocess.call(["bash", "-lc", "systemctl restart mas004-rpi-databridge.service"])
+        return {"ok": True}
+
+    @app.post("/api/outbox/enqueue")
+    def api_outbox_enqueue(req: OutboxEnqueue, x_token: Optional[str] = Header(default=None)):
+        cfg2 = Settings.load(cfg_path)
+        require_token(x_token, cfg2)
+
+        url = req.url if req.url else cfg2.peer_base_url.rstrip("/") + req.path
+        idem = outbox.enqueue(req.method, url, req.headers, req.body, req.idempotency_key)
+        return {"ok": True, "idempotency_key": idem}
+
+    @app.post("/api/inbox")
+    async def api_inbox(request: Request, x_idempotency_key: Optional[str] = Header(default=None)):
+        body = None
+        cfg2 = Settings.load(cfg_path)
+        if cfg2.shared_secret and x_shared_secret != cfg2.shared_secret:
+            raise HTTPException(status_code=401, detail="Unauthorized")        cfg2 = Settings.load(cfg_path)
+        if cfg2.shared_secret and x_shared_secret != cfg2.shared_secret:
+            raise HTTPException(status_code=401, detail="Unauthorized")
+        try:
+            body = await request.json()
+        except Exception:
+            body = None
+
+        headers = dict(request.headers)
+        idem = x_idempotency_key or headers.get("x-idempotency-key") or "missing"
+        source = request.client.host if request.client else None
+        inserted = inbox.store(source, headers, body, idem)
+        return {"ok": True, "stored": inserted, "idempotency_key": idem}
+
+    @app.get("/api/inbox/next")
+    def api_inbox_next(x_token: Optional[str] = Header(default=None)):
+        cfg2 = Settings.load(cfg_path)
+        require_token(x_token, cfg2)
+
+        msg = inbox.next_pending()
+        if not msg:
+            return {"ok": True, "msg": None}
+
+        return {
+            "ok": True,
+            "msg": {
+                "id": msg.id,
+                "received_ts": msg.received_ts,
+                "source": msg.source,
+                "headers_json": msg.headers_json,
+                "body_json": msg.body_json,
+                "idempotency_key": msg.idempotency_key,
+            },
+        }
+
+    @app.post("/api/inbox/{msg_id}/ack")
+    def api_inbox_ack(msg_id: int, x_token: Optional[str] = Header(default=None)):
+        cfg2 = Settings.load(cfg_path)
+        require_token(x_token, cfg2)
+        inbox.ack(msg_id)
+        return {"ok": True}
+
+    return app
diff --git a/pyproject.toml b/pyproject.toml
index a94a8e6..8db4c55 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,25 +1,25 @@
-[build-system]
-requires = ["setuptools>=69", "wheel"]
-build-backend = "setuptools.build_meta"
-
-[project]
-name = "MAS-004_RPI-Databridge"
-version = "0.1.0"
-description = "Reliable HTTPS send/receive on Raspberry Pi PLC with persistent inbox/outbox + watchdog + web UI"
-requires-python = ">=3.9"
-dependencies = [
-  "httpx>=0.27.0",
-  "fastapi>=0.110.0",
-  "uvicorn>=0.27.0",
-  "pydantic>=2.6.0",
-  "ping3>=4.0.0",
-]
-
-[project.optional-dependencies]
-dev = ["pytest>=8.0.0"]
-
-[project.scripts]
-mas004-databridge = "mas004_rpi_databridge.service:main"
-
-[tool.setuptools]
-packages = ["mas004_rpi_databridge"]
+[build-system]
+requires = ["setuptools>=69", "wheel"]
+build-backend = "setuptools.build_meta"
+
+[project]
+name = "MAS-004_RPI-Databridge"
+version = "0.1.0"
+description = "Reliable HTTPS send/receive on Raspberry Pi PLC with persistent inbox/outbox + watchdog + web UI"
+requires-python = ">=3.9"
+dependencies = [
+  "httpx>=0.27.0",
+  "fastapi>=0.110.0",
+  "uvicorn>=0.27.0",
+  "pydantic>=2.6.0",
+  "ping3>=4.0.0",
+]
+
+[project.optional-dependencies]
+dev = ["pytest>=8.0.0"]
+
+[project.scripts]
+mas004-databridge = "mas004_rpi_databridge.service:main"
+
+[tool.setuptools]
+packages = ["mas004_rpi_databridge"]
diff --git a/scripts/config.example.json b/scripts/config.example.json
index 731e72c..d360a0b 100644
--- a/scripts/config.example.json
+++ b/scripts/config.example.json
@@ -1,41 +1,41 @@
-{
-  "db_path": "/var/lib/mas004_rpi_databridge/databridge.db",
-  "webui_host": "0.0.0.0",
-  "webui_port": 8080,
-
-  "eth0_ip": "192.168.1.100",
-  "eth0_subnet": "24",
-  "eth0_gateway": "192.168.1.1",
-
-  "eth1_ip": "192.168.2.100",
-  "eth1_subnet": "24",
-  "eth1_gateway": "192.168.2.1",
-
-  "eth0_source_ip": "",
-
-  "peer_base_url": "http://192.168.1.64:9090",
-  "peer_watchdog_host": "192.168.1.64",
-  "peer_health_path": "/health",
-
-  "watchdog_interval_s": 2.0,
-  "watchdog_timeout_s": 1.0,
-  "watchdog_down_after": 3,
-
-  "http_timeout_s": 10.0,
-  "tls_verify": false,
-
-  "retry_base_s": 1.0,
-  "retry_cap_s": 60.0,
-
-  "ui_token": "SET_ME",
-  "shared_secret": "SET_ME_OR_EMPTY",
-
-  "esp_host": "192.168.2.10",
-  "esp_port": 5000,
-
-  "vj3350_host": "192.168.2.20",
-  "vj3350_port": 20000,
-
-  "vj6530_host": "192.168.2.30",
-  "vj6530_port": 3007
-}
+{
+  "db_path": "/var/lib/mas004_rpi_databridge/databridge.db",
+  "webui_host": "0.0.0.0",
+  "webui_port": 8080,
+
+  "eth0_ip": "192.168.1.100",
+  "eth0_subnet": "24",
+  "eth0_gateway": "192.168.1.1",
+
+  "eth1_ip": "192.168.2.100",
+  "eth1_subnet": "24",
+  "eth1_gateway": "192.168.2.1",
+
+  "eth0_source_ip": "",
+
+  "peer_base_url": "http://192.168.1.64:9090",
+  "peer_watchdog_host": "192.168.1.64",
+  "peer_health_path": "/health",
+
+  "watchdog_interval_s": 2.0,
+  "watchdog_timeout_s": 1.0,
+  "watchdog_down_after": 3,
+
+  "http_timeout_s": 10.0,
+  "tls_verify": false,
+
+  "retry_base_s": 1.0,
+  "retry_cap_s": 60.0,
+
+  "ui_token": "SET_ME",
+  "shared_secret": "SET_ME_OR_EMPTY",
+
+  "esp_host": "192.168.2.10",
+  "esp_port": 5000,
+
+  "vj3350_host": "192.168.2.20",
+  "vj3350_port": 20000,
+
+  "vj6530_host": "192.168.2.30",
+  "vj6530_port": 3007
+}
diff --git a/scripts/default_config.json b/scripts/default_config.json
index 07226df..cad15ee 100644
--- a/scripts/default_config.json
+++ b/scripts/default_config.json
@@ -1,19 +1,19 @@
-{
-  "db_path": "/var/lib/mas004_rpi_databridge/databridge.db",
-  "webui_host": "0.0.0.0",
-  "webui_port": 8080,
-  "eth0_ip": "192.168.1.100",
-  "eth1_ip": "192.168.2.100",
-  "eth0_source_ip": "192.168.1.100",
-  "peer_base_url": "https://192.168.1.10",
-  "peer_watchdog_host": "192.168.1.10",
-  "peer_health_path": "/health",
-  "watchdog_interval_s": 2.0,
-  "watchdog_timeout_s": 1.0,
-  "watchdog_down_after": 3,
-  "http_timeout_s": 10.0,
-  "tls_verify": true,
-  "retry_base_s": 1.0,
-  "retry_cap_s": 60.0,
-  "ui_token": "change-me"
-}
+{
+  "db_path": "/var/lib/mas004_rpi_databridge/databridge.db",
+  "webui_host": "0.0.0.0",
+  "webui_port": 8080,
+  "eth0_ip": "192.168.1.100",
+  "eth1_ip": "192.168.2.100",
+  "eth0_source_ip": "192.168.1.100",
+  "peer_base_url": "https://192.168.1.10",
+  "peer_watchdog_host": "192.168.1.10",
+  "peer_health_path": "/health",
+  "watchdog_interval_s": 2.0,
+  "watchdog_timeout_s": 1.0,
+  "watchdog_down_after": 3,
+  "http_timeout_s": 10.0,
+  "tls_verify": true,
+  "retry_base_s": 1.0,
+  "retry_cap_s": 60.0,
+  "ui_token": "change-me"
+}
diff --git a/scripts/install.sh b/scripts/install.sh
index 51a5b61..7c9551d 100755
--- a/scripts/install.sh
+++ b/scripts/install.sh
@@ -1,23 +1,23 @@
-#!/usr/bin/env bash
-set -e
-
-sudo apt-get update
-sudo apt-get install -y python3-venv python3-pip sqlite3
-
-sudo mkdir -p /etc/mas004_rpi_databridge /var/lib/mas004_rpi_databridge
-
-python3 -m venv .venv
-. .venv/bin/activate
-pip install -U pip
-pip install -e .
-
-if [ ! -f /etc/mas004_rpi_databridge/config.json ]; then
-  sudo cp scripts/default_config.json /etc/mas004_rpi_databridge/config.json
-fi
-
-sudo cp systemd/mas004-rpi-databridge.service /etc/systemd/system/mas004-rpi-databridge.service
-sudo systemctl daemon-reload
-sudo systemctl enable --now mas004-rpi-databridge.service
-
-echo "Web UI: http://192.168.1.100:8080"
-echo "Logs: journalctl -u mas004-rpi-databridge.service -f"
+#!/usr/bin/env bash
+set -e
+
+sudo apt-get update
+sudo apt-get install -y python3-venv python3-pip sqlite3
+
+sudo mkdir -p /etc/mas004_rpi_databridge /var/lib/mas004_rpi_databridge
+
+python3 -m venv .venv
+. .venv/bin/activate
+pip install -U pip
+pip install -e .
+
+if [ ! -f /etc/mas004_rpi_databridge/config.json ]; then
+  sudo cp scripts/default_config.json /etc/mas004_rpi_databridge/config.json
+fi
+
+sudo cp systemd/mas004-rpi-databridge.service /etc/systemd/system/mas004-rpi-databridge.service
+sudo systemctl daemon-reload
+sudo systemctl enable --now mas004-rpi-databridge.service
+
+echo "Web UI: http://192.168.1.100:8080"
+echo "Logs: journalctl -u mas004-rpi-databridge.service -f"
diff --git a/systemd/mas004-rpi-databridge.service b/systemd/mas004-rpi-databridge.service
index 7e2a463..53c7c36 100644
--- a/systemd/mas004-rpi-databridge.service
+++ b/systemd/mas004-rpi-databridge.service
@@ -1,17 +1,17 @@
-[Unit]
-Description=MAS-004_RPI-Databridge (reliable HTTPS send/receive + watchdog + web UI)
-After=network-online.target
-Wants=network-online.target
-
-[Service]
-Type=simple
-User=root
-WorkingDirectory=/opt/MAS-004_RPI-Databridge
-ExecStart=/opt/MAS-004_RPI-Databridge/.venv/bin/mas004-databridge
-Restart=always
-RestartSec=2
-StandardOutput=journal
-StandardError=journal
-
-[Install]
-WantedBy=multi-user.target
+[Unit]
+Description=MAS-004_RPI-Databridge (reliable HTTPS send/receive + watchdog + web UI)
+After=network-online.target
+Wants=network-online.target
+
+[Service]
+Type=simple
+User=root
+WorkingDirectory=/opt/MAS-004_RPI-Databridge
+ExecStart=/opt/MAS-004_RPI-Databridge/.venv/bin/mas004-databridge
+Restart=always
+RestartSec=2
+StandardOutput=journal
+StandardError=journal
+
+[Install]
+WantedBy=multi-user.target
